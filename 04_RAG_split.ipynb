{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r5KJwOhkl8kQ",
        "3E1bJD9JmGK9",
        "E2EIf0ZLmQ1z",
        "tRs6vCVhnE3c",
        "2qElk4tJu4GJ",
        "JGbMKmyNvgfa",
        "SuP7Qf5zwCNI",
        "ngAAoKwsvQs8",
        "66ur5HREvWQ4"
      ],
      "mount_file_id": "1N5OEjnRU0JrdwiD7269r6JJSFg1xkrfU",
      "authorship_tag": "ABX9TyNhk9/YL2yYFIaiyBli6ZpD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genie0320/langchain/blob/main/04_RAG_split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "r5KJwOhkl8kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colab 환경설정\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "#   f.write('Hello Google Drive!')\n",
        "# !cat '/gdrive/My Drive/foo.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo5Aoy-IyS36",
        "outputId": "8e9e79ec-b6c9-4a25-a70b-0aa70ab55e8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "# api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "fC6KTxHBzdtg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load utills"
      ],
      "metadata": {
        "id": "3E1bJD9JmGK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet icecream"
      ],
      "metadata": {
        "id": "vsqi-QCSmB-z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "from icecream import ic\n",
        "\n",
        "def pp(object):\n",
        "  ppr = pprint.PrettyPrinter(\n",
        "      # indent=40,\n",
        "      width=80\n",
        "      )\n",
        "  return ppr.pprint(object)"
      ],
      "metadata": {
        "id": "U2CeiFFOmAuK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function KeepClicking(){ console.log(\"Clicking\"); document.querySelector(\"colab-connect-button\").click() } setInterval(KeepClicking,60000)"
      ],
      "metadata": {
        "id": "zR142t2zmNji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model setting"
      ],
      "metadata": {
        "id": "E2EIf0ZLmQ1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_sqJeLanmVhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q langchain_openai"
      ],
      "metadata": {
        "id": "_8fs5aIlmsVc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ___ setting ___\n",
        "LLM_MODEL = \"gpt-3.5-turbo\"\n",
        "MAX = 50\n",
        "TEMP = 1.5\n",
        "# _______________\n",
        "\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_compbot = OpenAI(\n",
        "    temperature=TEMP,\n",
        "    max_tokens = MAX,\n",
        "    verbose = True,\n",
        ")\n",
        "openai_chatbot = ChatOpenAI(\n",
        "    temperature=TEMP,\n",
        "    max_tokens = MAX,\n",
        "    verbose = True,\n",
        ")"
      ],
      "metadata": {
        "id": "_pqU6f5jm3tl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ic(openai_compbot.invoke('hi'))\n",
        "ic(openai_chatbot.invoke('hi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcmIz_oim9te",
        "outputId": "eefbbf6b-157e-4ee6-c852-e2447da7c99c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| openai_compbot.invoke('hi'): ('\n",
            "                                 '\n",
            "                                  '52526\n",
            "                                 '\n",
            "                                  '\n",
            "                                 '\n",
            "                                  '     \n",
            "                                 '\n",
            "                                  '\n",
            "                                 '\n",
            "                                  \"Interesting Post. – washaq Jul 31 '09 at 17:50\n",
            "                                 \"\n",
            "                                  '\n",
            "                                 '\n",
            "                                  '     \n",
            "                                 '\n",
            "                                  '\n",
            "                                 '\n",
            "                                  'Thanks crash31. This what flushed debate a styles fall forward as went linux '\n",
            "                                  'change me tiended whenever utility only to down rattled')\n",
            "ic| openai_chatbot.invoke('hi'): AIMessage(content='Hello! How can I assist you today?')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Comletion\n",
        "# prompt = PromptTemplate.from_template( '{time} + \\n\\n text{name} +  {action}')\n",
        "# user_input = 'Where shall we go today?'\n",
        "# new_prompt = prompt.format(\n",
        "#     time = \"old\",\n",
        "#     name = \"Genie\",\n",
        "#     action = user_input\n",
        "# )\n",
        "# res_llm = llm.invoke(new_prompt)\n",
        "\n",
        "# # Chat\n",
        "# template = \"You are my new friend. We met {place} for {activity}.\"\n",
        "# human_template = \"{text}\"\n",
        "# chat_prompt = ChatPromptTemplate.from_messages([\n",
        "#     (\"system\", template), # 값을 tuple로 전달.\n",
        "#     (\"human\", human_template),\n",
        "# ])\n",
        "\n",
        "# prompt = chat_prompt.format_messages(place=\"in library\", activity=\"being a study friend\", text=\"Hey, Sweety!\")\n",
        "# res_chat = chat_model.invoke(prompt).content"
      ],
      "metadata": {
        "id": "ZCBffRk90LQH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(prompt)\n",
        "# print(res_chat)"
      ],
      "metadata": {
        "id": "AQA49rnW0N4o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG setting"
      ],
      "metadata": {
        "id": "Z5-tmjkAnA24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loader\n",
        "\n",
        "- [ ] 웹페이지 로딩\n",
        "- [ ] 옵시디언 로딩\n",
        "- [ ] 노션 로딩\n",
        "- [ ] `from langchain_community.document_loaders import UnstructuredPDFLoader`"
      ],
      "metadata": {
        "id": "tRs6vCVhnE3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_folder = \"/content/source\"\n",
        "SOURCE = \"/content/source/1-1그로스 해킹, 마케팅과 어떻게 다른가요_ - PUBLY.pdf\""
      ],
      "metadata": {
        "id": "_oRD4j_otisK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain_community\n",
        "# !pip install -q pypdf"
      ],
      "metadata": {
        "id": "sBFcnWJtnKru"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파일불러오기"
      ],
      "metadata": {
        "id": "8k-aRhwLBLGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 폴더째로 불러오기"
      ],
      "metadata": {
        "id": "1s1jJQPg87vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] `documents = loader.load()`, `pages = loader.load_and_split()` 의 차이는?"
      ],
      "metadata": {
        "id": "OY9u2bT2FCT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "loader = DirectoryLoader(SOURCE_folder, glob='**/*.pdf', show_progress=True, loader_cls=PyPDFLoader)\n",
        "# documents = loader.load()\n",
        "# print(len(documents), '\\n\\n', documents[0])\n",
        "pages = loader.load_and_split()\n",
        "print(len(pages), '\\n\\n', pages[0])\n",
        "\n",
        "# 위의 둘은 결과적으로 똑같다. 그러나 아래것이 조금 더 빠르다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5clBfisannC2",
        "outputId": "a97ce8ae-0f44-400a-b6b9-73f8de1db01c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:16<00:00,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 \n",
            "\n",
            " page_content=\"24. 2. 9. 오후  9:49 가설 검증은  비즈니스의  기본이다 : 조금  잃고  많이  따는  법  - PUBLY\\nhttps://publy.co/content/4608?fr=set-bottom-list 1/13가설 검증은 비즈니스의 기본이다: 조금 잃고\\n많이 따는 법\\n저자김민우\\n마케팅 트렌드/실무서비스 기획/데이터/UX\\n5,864명이 봤어요 • 91% 만족\\n과학시간도 아니고 웬 가설?\\nEditor's Comment\\n이번 웹북의 제목 '리스크를 줄이는 그로스해킹 전략: 퍼블리는 A/B 테스트를 어떻게 하고 있나'은 퍼블리 고객분들을\\n대상으로 설문조사를 해 정해진 제목입니다. 퍼블리는 앞으로도 고객 여러분들의 의견을 적극 반영해 콘텐츠에 만족하실\\n수 있도록 노력하겠습니다.\\n저자 김민우\\n그로스 컨설턴트, (전)퍼블리 VP of Growth > 프로필 더 보기\\n가설 수립과 가설 검증. 아마 학창 시절 과학 시간 이후로 들을 일도 말할 일도 없었던 개념들일\\n것입니다. 벌써 학교를 졸업한 우리가 왜 가설에 대해 알아야 할까요? 그 이유는 그로스의 핵심,\\n더 본질적으로는 스타트업의 핵심이 가설을 수립하고, 검증하며 배움을 얻는 것이기 때문입니다.\\n \\n여러분은 스타트업이 무엇이라고 생각하시나요? 그리고 스타트업에서 일하는 것에는 어떤\\n의미가 있다고 생각하시나요? 스타트업이 무엇인지, 그 정의를 이해하면 가설 수립과 검증의\\n중요성 역시 이해할 수 있습니다.\\n \\n스타트업이 무엇인지 사람들에게 묻는다면, 일반적으로 다음과 같은 대답이 나올 것입니다.\\n새로운 기술로 혁신적인 사업을 하는 회사\\n젊은 사람들이 일하는 회사\\n자유로운 분위기를 가진 회사\\n새로 시작해서 규모가 작은 회사\\n그러나 저는 이런 요소들이 스타트업 중 일부가 가진 속성일 수는 있어도, 스타트업을 규정하는\\n본질적 요소는 아니라고 생각합니다.\\n \\n스타트업을 위한 경영학이라 할 수 있는 고객 개발(customer development) 방법론을\\n가르치는 스티브 블랭크(Steve Blank)는 스타트업을 이렇게 정의합니다.\" metadata={'source': '/content/source/2-3가설 검증은 비즈니스의 기본이다_ 조금 잃고 많이 따는 법 - PUBLY.pdf', 'page': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 파일 하나 불러오기"
      ],
      "metadata": {
        "id": "PCFUa6WW8txW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이건 PDF\n",
        "# from langchain_community.document_loaders import PyPDFLoader\n",
        "# loader = PyPDFLoader(SOURCE)\n",
        "# pages = loader.load_and_split()\n",
        "# print(len(pages), '\\n\\n', pages[0])"
      ],
      "metadata": {
        "id": "ZNgeIrFHnVP_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이건 뭔...지\n",
        "# with open(\"../../state_of_the_union.txt\") as f: # 이건 로컬파일일 때...이야기인가. loader와 무슨 관계?\n",
        "#     state_of_the_union = f.read()"
      ],
      "metadata": {
        "id": "_s7ke_fPnaAq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WORD 파일"
      ],
      "metadata": {
        "id": "8b7kdtabFR26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Docx2TextLoader\n",
        "# CSVLoader : 이건 좀 사용법이 다르다.\n"
      ],
      "metadata": {
        "id": "uoUQ26fAFVNV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 웹페이지 불러오기"
      ],
      "metadata": {
        "id": "xamCUBZq-Ajh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TARGET_URL = 'https://blog.ab180.co/posts/growth-hacking-5-features'\n",
        "# TARGET_URLS = [\n",
        "#     'https://blog.ab180.co/posts/growth-hacking-5-features',\n",
        "#     'https://dbr.donga.com/article/view/1202/article_no/9026/ac/magazine',\n",
        "#     'https://blog.hsad.co.kr/3323',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%eb%a7%88%ec%bc%80%ed%8c%85%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83/',\n",
        "#     'https://groobee.net/blog/%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4%EB%A5%BC-%EC%9C%84%ED%95%9C-%ED%95%B5%EC%8B%AC-%EC%A0%84%EB%9E%B5-%EA%B7%B8%EB%A1%9C%EC%8A%A4-%ED%95%B4%ED%82%B9%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B2%83-2/',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%ed%95%b4%ed%82%b9%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83-3/',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%ed%95%b4%ed%82%b9%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83-4/',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%ed%95%b4%ed%82%b9%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83-5/',\n",
        "#     'https://groobee.net/blog/%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4%EB%A5%BC-%EC%9C%84%ED%95%9C-%ED%95%B5%EC%8B%AC-%EC%A0%84%EB%9E%B5-%EA%B7%B8%EB%A1%9C%EC%8A%A4-%ED%95%B4%ED%82%B9%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B2%83-6/'\n",
        "# ]"
      ],
      "metadata": {
        "id": "ucbMZfDW-N26"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 한페이지 불러오기"
      ],
      "metadata": {
        "id": "l1cb7AL1BCBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import WebBaseLoader\n",
        "# loader = WebBaseLoader(TARGET_URL)\n",
        "\n",
        "# web_data = loader.load()\n",
        "# print(len(web_data), '\\n', web_data[0])"
      ],
      "metadata": {
        "id": "m5EIhdp2-Crj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 여러페이지 불러오기"
      ],
      "metadata": {
        "id": "-ZJae6lfA_9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "한번에 많이 가져올 수 있어서 좋으나... 결과물이 좀 더럽다."
      ],
      "metadata": {
        "id": "FQgHzt20EJOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q unstructured"
      ],
      "metadata": {
        "id": "wRoY0PixDD42"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import UnstructuredURLLoader\n",
        "# loader = UnstructuredURLLoader(urls = TARGET_URLS)\n",
        "# web_datas = loader.load()"
      ],
      "metadata": {
        "id": "7u566kHFA5bG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(web_datas), '\\n', web_datas[0])"
      ],
      "metadata": {
        "id": "Pw6qXnzkDUhV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 모양 살펴보기"
      ],
      "metadata": {
        "id": "hKiDDyER81eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for p in pages[0:10]:\n",
        "#     with open('/content/drive/MyDrive/bar_split.txt', 'a') as f:\n",
        "#         f.write(p.page_content)\n",
        "# # # !cat '/gdrive/My Drive/foo.txt'"
      ],
      "metadata": {
        "id": "FF2zEOc46FQP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 줄바꿈등 제거하기"
      ],
      "metadata": {
        "id": "xbfYFb949T60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: 줄바꿈 등을 제거한 후"
      ],
      "metadata": {
        "id": "FgA0t_7ctx04"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitter"
      ],
      "metadata": {
        "id": "gxJaLocungLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] `# from langchain_experimental.text_splitter import SemanticChunker > 이건 openai의 실험적 기능이라는데... 한번 써보고 싶음.`"
      ],
      "metadata": {
        "id": "wq1tHm1KoqIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain_core langchain_community\n",
        "# !pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "L-o03gp2mWMX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 글자수로 맞춰 분할."
      ],
      "metadata": {
        "id": "lf0L3sqTc7k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loader : pages\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = '\\n',\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 100,\n",
        "    length_function= len # 이 경우, 단순히 글자수를 기준으로 1000을 세라는 것.\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(pages) # 얘는 배열 그대로를 처리할 수 있다.\n",
        "# texts= text_splitter.split_text(pages) # 얘는 str이어야 함.\n",
        "chunks[0]"
      ],
      "metadata": {
        "id": "dfcHoyNTno6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e261864b-d28d-4612-885a-640716eecbe3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"24. 2. 9. 오후  9:49 가설 검증은  비즈니스의  기본이다 : 조금  잃고  많이  따는  법  - PUBLY\\nhttps://publy.co/content/4608?fr=set-bottom-list 1/13가설 검증은 비즈니스의 기본이다: 조금 잃고\\n많이 따는 법\\n저자김민우\\n마케팅 트렌드/실무서비스 기획/데이터/UX\\n5,864명이 봤어요 • 91% 만족\\n과학시간도 아니고 웬 가설?\\nEditor's Comment\\n이번 웹북의 제목 '리스크를 줄이는 그로스해킹 전략: 퍼블리는 A/B 테스트를 어떻게 하고 있나'은 퍼블리 고객분들을\\n대상으로 설문조사를 해 정해진 제목입니다. 퍼블리는 앞으로도 고객 여러분들의 의견을 적극 반영해 콘텐츠에 만족하실\\n수 있도록 노력하겠습니다.\\n저자 김민우\\n그로스 컨설턴트, (전)퍼블리 VP of Growth > 프로필 더 보기\\n가설 수립과 가설 검증. 아마 학창 시절 과학 시간 이후로 들을 일도 말할 일도 없었던 개념들일\\n것입니다. 벌써 학교를 졸업한 우리가 왜 가설에 대해 알아야 할까요? 그 이유는 그로스의 핵심,\\n더 본질적으로는 스타트업의 핵심이 가설을 수립하고, 검증하며 배움을 얻는 것이기 때문입니다.\\n \\n여러분은 스타트업이 무엇이라고 생각하시나요? 그리고 스타트업에서 일하는 것에는 어떤\\n의미가 있다고 생각하시나요? 스타트업이 무엇인지, 그 정의를 이해하면 가설 수립과 검증의\\n중요성 역시 이해할 수 있습니다.\\n \\n스타트업이 무엇인지 사람들에게 묻는다면, 일반적으로 다음과 같은 대답이 나올 것입니다.\\n새로운 기술로 혁신적인 사업을 하는 회사\\n젊은 사람들이 일하는 회사\\n자유로운 분위기를 가진 회사\\n새로 시작해서 규모가 작은 회사\\n그러나 저는 이런 요소들이 스타트업 중 일부가 가진 속성일 수는 있어도, 스타트업을 규정하는\\n본질적 요소는 아니라고 생각합니다.\\n \\n스타트업을 위한 경영학이라 할 수 있는 고객 개발(customer development) 방법론을\", metadata={'source': '/content/source/2-3가설 검증은 비즈니스의 기본이다_ 조금 잃고 많이 따는 법 - PUBLY.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tzytleGHadL",
        "outputId": "202aed24-fad4-4ce9-a485-b0551181bece"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens = []\n",
        "for n in chunks:\n",
        "    lens.append(len(n.page_content))\n",
        "print(sorted(lens, reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emZSLk3BHxBS",
        "outputId": "28808a70-e8f7-42a4-e6ea-5d17ea7feed2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000, 1000, 1000, 1000, 999, 998, 998, 997, 997, 994, 992, 992, 991, 991, 989, 989, 989, 988, 988, 987, 986, 986, 984, 984, 983, 983, 983, 982, 982, 982, 981, 980, 979, 978, 977, 975, 975, 975, 974, 974, 973, 972, 970, 969, 969, 968, 968, 965, 965, 965, 965, 962, 960, 960, 957, 954, 952, 950, 947, 938, 932, 927, 905, 898, 892, 866, 864, 859, 843, 834, 827, 820, 816, 811, 801, 776, 756, 730, 702, 702, 701, 663, 659, 651, 646, 645, 636, 624, 621, 603, 601, 594, 575, 573, 567, 559, 538, 526, 521, 504, 502, 491, 483, 470, 416, 408, 404, 401, 401, 396, 395, 368, 359, 358, 330, 318, 288, 268, 249, 234, 226, 192, 166, 156, 156, 151, 142, 120, 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 재귀적으로 분할... 그러나...."
      ],
      "metadata": {
        "id": "8uVyBkSvc3od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 적정한 길이로 잘라주고\n",
        "rc_splitter = RecursiveCharacterTextSplitter(\n",
        "    # separator=\"\\n\\n\", : 이 옵션은 의미가 없다. 알아서 맞춰서 잘라준다.\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "docs = []\n",
        "for document in pages:\n",
        "    docs.append(document.page_content)\n",
        "\n",
        "# texts = splitter.split_documents(pages) # 단순 커터\n",
        "rc_chunks = rc_splitter.create_documents(docs) # 옵션을 줄 수 있다. []을 받는다.\n"
      ],
      "metadata": {
        "id": "ZOQMre6sIWDZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token 길이에 맞춰 분할"
      ],
      "metadata": {
        "id": "4syk8Xtjcw_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q tiktoken"
      ],
      "metadata": {
        "id": "0O7QniQwSE3Q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# token 단위로 분할하는 기능\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base') # openai에서 사용하는 규약이라고 함.\n",
        "\n",
        "# 해당 텍스트를 처리하기 위한 token의 수를 세는 함수\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    return len(tokens)\n",
        "\n",
        "tiktoken_len(pages[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04oDXfxZG2uU",
        "outputId": "fe3d5694-daed-4636-a118-268897e01180"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "911"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rc_t_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder( > 이런 것도 있다던데.\n",
        "rc_t_splitter = RecursiveCharacterTextSplitter(\n",
        "    is_separator_regex=False,\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=tiktoken_len,# 얘는 토큰길이에 따름.\n",
        ")"
      ],
      "metadata": {
        "id": "bneJnOl_S6Ig"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk_chunks = rc_t_splitter.split_documents(pages)\n",
        "len(tk_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRN_bSbJpRd5",
        "outputId": "484dee94-5356-4d60-f303-417af9dc5a4d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tk_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb3uaqEGpWcb",
        "outputId": "b453760b-ff68-4fb4-c89e-24b56f166c78"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"24. 2. 9. 오후  9:49 가설 검증은  비즈니스의  기본이다 : 조금  잃고  많이  따는  법  - PUBLY\\nhttps://publy.co/content/4608?fr=set-bottom-list 1/13가설 검증은 비즈니스의 기본이다: 조금 잃고\\n많이 따는 법\\n저자김민우\\n마케팅 트렌드/실무서비스 기획/데이터/UX\\n5,864명이 봤어요 • 91% 만족\\n과학시간도 아니고 웬 가설?\\nEditor's Comment\\n이번 웹북의 제목 '리스크를 줄이는 그로스해킹 전략: 퍼블리는 A/B 테스트를 어떻게 하고 있나'은 퍼블리 고객분들을\\n대상으로 설문조사를 해 정해진 제목입니다. 퍼블리는 앞으로도 고객 여러분들의 의견을 적극 반영해 콘텐츠에 만족하실\\n수 있도록 노력하겠습니다.\\n저자 김민우\\n그로스 컨설턴트, (전)퍼블리 VP of Growth > 프로필 더 보기\\n가설 수립과 가설 검증. 아마 학창 시절 과학 시간 이후로 들을 일도 말할 일도 없었던 개념들일\\n것입니다. 벌써 학교를 졸업한 우리가 왜 가설에 대해 알아야 할까요? 그 이유는 그로스의 핵심,\\n더 본질적으로는 스타트업의 핵심이 가설을 수립하고, 검증하며 배움을 얻는 것이기 때문입니다.\\n \\n여러분은 스타트업이 무엇이라고 생각하시나요? 그리고 스타트업에서 일하는 것에는 어떤\\n의미가 있다고 생각하시나요? 스타트업이 무엇인지, 그 정의를 이해하면 가설 수립과 검증의\\n중요성 역시 이해할 수 있습니다.\\n \\n스타트업이 무엇인지 사람들에게 묻는다면, 일반적으로 다음과 같은 대답이 나올 것입니다.\\n새로운 기술로 혁신적인 사업을 하는 회사\\n젊은 사람들이 일하는 회사\\n자유로운 분위기를 가진 회사\\n새로 시작해서 규모가 작은 회사\\n그러나 저는 이런 요소들이 스타트업 중 일부가 가진 속성일 수는 있어도, 스타트업을 규정하는\\n본질적 요소는 아니라고 생각합니다.\\n \\n스타트업을 위한 경영학이라 할 수 있는 고객 개발(customer development) 방법론을\\n가르치는 스티브 블랭크(Steve Blank)는 스타트업을 이렇게 정의합니다.\", metadata={'source': '/content/source/2-3가설 검증은 비즈니스의 기본이다_ 조금 잃고 많이 따는 법 - PUBLY.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tk_lens = []\n",
        "for n in tk_chunks:\n",
        "    tk_lens.append(len(n.page_content))\n",
        "print(sorted(tk_lens, reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KErhl6b-Cz",
        "outputId": "e865277f-130d-4fd8-ad7d-1ac32f180562"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1223, 1208, 1179, 1178, 1166, 1165, 1161, 1161, 1154, 1151, 1142, 1139, 1137, 1135, 1127, 1124, 1121, 1119, 1119, 1115, 1113, 1112, 1099, 1098, 1094, 1094, 1093, 1090, 1086, 1086, 1083, 1081, 1080, 1080, 1079, 1077, 1073, 1072, 1071, 1071, 1064, 1058, 1056, 1053, 1052, 1051, 1050, 1048, 1047, 1045, 1043, 1042, 1037, 1034, 1027, 1004, 1000, 987, 965, 938, 913, 905, 892, 864, 859, 827, 790, 784, 783, 758, 756, 754, 725, 712, 702, 694, 663, 653, 646, 640, 623, 606, 603, 597, 544, 538, 532, 521, 519, 517, 513, 512, 506, 504, 502, 499, 478, 467, 459, 425, 408, 399, 368, 358, 352, 330, 317, 302, 301, 279, 263, 259, 240, 208, 176, 176, 163, 117, 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding / Saving"
      ],
      "metadata": {
        "id": "zDjBlW-GouwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NNjJgsR5oubG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB_URL = 'store/openai/publy'"
      ],
      "metadata": {
        "id": "c3IEhglprqq8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "# chroma_client = chromadb.Client() > 이건 뭐에 필요한 것인지..."
      ],
      "metadata": {
        "id": "LNZVPioBqrSX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_openai import OpenAIEmbeddings\n",
        "# openai_embed = OpenAIEmbeddings()\n",
        "# vector_stores = Chroma.from_documents(texts, openai_embed)\n",
        "# vector_stores = Chroma.from_documents(\n",
        "#     texts,\n",
        "#     openai_embed,\n",
        "#     persist_directory = DB_URL\n",
        "# )\n",
        "# print('openai_embed : Document Stored!!')"
      ],
      "metadata": {
        "id": "7bml4DpTn-kO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(openai_embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "hFOW3VJbrTyu",
        "outputId": "3624c3ba-8337-4507-ecec-3f1d5aa8239e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'openai_embed' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-6faf29c83099>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopenai_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'openai_embed' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "hug_embed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# hug_embed = HuggingFaceEmbeddings(model_name=\"BlinkDL/rwkv-5-world\")\n",
        "# vector_stores = Chroma.from_documents(texts, hug_embed)\n",
        "vector_stores = Chroma.from_documents(\n",
        "    texts,\n",
        "    hug_embed,\n",
        "    persist_directory = DB_URL\n",
        ")\n",
        "print('hug_embed : Document Stored!!')"
      ],
      "metadata": {
        "id": "LZ-dw9wso_9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hug_embed)"
      ],
      "metadata": {
        "id": "uQAlTElfno0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------"
      ],
      "metadata": {
        "id": "ZKZ21_KvtFHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval"
      ],
      "metadata": {
        "id": "jVum-LKHreM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그리고 retreiver를 만들어서\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "from_db = Chroma(persist_directory=DB_URL, embedding_function=embedding)\n",
        "retriever = from_db.as_retriever(search_type = 'similarity', search_kwargs={'k' :2})\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "XSaXs3XHuZzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Retrieve from DB\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever"
      ],
      "metadata": {
        "id": "dkbQ4J7EsQeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_vector_store = Chroma(\n",
        "    persist_directory = DIRECT,\n",
        "    embedding_function = embeddings,\n",
        "    )"
      ],
      "metadata": {
        "id": "L5-b1b2_rdjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = load_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "9LbMi4a2sAxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input_embedding = input('검색할 키워드 입력 :')\n",
        "query = user_input_embedding\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "j5gHt2PYpL1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input_multiquery = input('검색할 키워드 입력 :')\n",
        "# question = user_input_multiquery\n",
        "# llm = chat_model\n",
        "\n",
        "# retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "#     retriever=db.as_retriever(), llm=llm\n",
        "# )\n",
        "# print(retriever_from_llm)\n",
        "# print(len(res))\n",
        "# res = retriever_from_llm.get_relevant_documents(query = question)"
      ],
      "metadata": {
        "id": "_pUb2xu5sVkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = '팀장과 팀원의 차이는?'"
      ],
      "metadata": {
        "id": "f5AknkyMrqWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(query)\n",
        "print(len(docs), docs[0])"
      ],
      "metadata": {
        "id": "S6uZMMl2nora"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = []\n",
        "for d in docs:\n",
        "    context.append(d.page_content)\n",
        "context"
      ],
      "metadata": {
        "id": "4XyNZGtqug2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making QA chain"
      ],
      "metadata": {
        "id": "a2DkROL9usnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "# RAG 체인을 만들고\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=ask_openai(), chain_type='stuff', retriever = retriever, return_source_documents=True\n",
        ")\n",
        "\n",
        "# 질문을 하면 된다.\n",
        "rerult = qa({'query': user_input})\n",
        "\n",
        "# print results\n",
        "rerult"
      ],
      "metadata": {
        "id": "BbyWl617ur-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Answer"
      ],
      "metadata": {
        "id": "QiliGhS5s01U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Make answer with LLM\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "user_input_multiquery = input('검색할 키워드 입력 :')\n",
        "question = user_input_multiquery\n",
        "llm = chat_model\n",
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())\n",
        "result = qa_chain.invoke({'query':question})\n",
        "# print(result)\n",
        "print(result['result'])"
      ],
      "metadata": {
        "id": "06qpWy54s8qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "lNgoix8bkBWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template('''\n",
        "Use following context to answer the user's question in Korean.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "---------------------\n",
        "Context :{context_str}\n",
        "---------------------\n",
        "\n",
        "Question: {query_str}\n",
        "\n",
        "Only return the helpful answer below and nothing else.\n",
        "Answer:\n",
        "''')"
      ],
      "metadata": {
        "id": "NMp7XeTNkzx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"팀장과 팀원의 차이는?\""
      ],
      "metadata": {
        "id": "chLQmY2p8Vll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = prompt_template.format(\n",
        "#     context_str = context,\n",
        "#     query_str = question\n",
        "#     )"
      ],
      "metadata": {
        "id": "UCtL9S4xlNop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"google/flan-t5-xxl\"\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,\n",
        "    repo_id = repo_id,\n",
        "    model_kwargs = {'temperature':0.3, \"max_length\" : 500}\n",
        ")"
      ],
      "metadata": {
        "id": "eDNmjQvnyEEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchainhub"
      ],
      "metadata": {
        "id": "nUIE9fsc9MsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")"
      ],
      "metadata": {
        "id": "tWJT2HMo9FcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint"
      ],
      "metadata": {
        "id": "0x3JSjHm9gUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pprint(prompt)\n",
        "prompt"
      ],
      "metadata": {
        "id": "9qH1eWYa9RDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type='stuff',\n",
        "    retriever = retriever,\n",
        "    return_source_documents = True,\n",
        "    chain_type_kwargs = chain_type_kwargs,\n",
        "    verbose = True\n",
        ")\n",
        "\n",
        "# qa_chain = RetrievalQA.from_chain_type(\n",
        "#     llm,\n",
        "#     retriever=retriever,\n",
        "#     chain_type_kwargs={\"prompt\": prompt},\n",
        "#     verbose = True\n",
        "# )\n",
        "\n",
        "question = \"팀장과 팀원의 차이는?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "lWuBispVyxZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이 모든 것을 한번에 해결해주는... VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "2qElk4tJu4GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "index = VectorstoreIndexCreator(\n",
        "    # 텍스트를 자르고+\n",
        "    text_splitter=splitter,\n",
        "    # 임베딩처리를 하고\n",
        "    embedding = embedding,\n",
        "    # Chroma에 로딩한다.\n",
        "    vectorstore_cls=Chroma\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "id": "tJMIuCd2u42t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.query(\n",
        "    llm = ask_openai(),\n",
        "    question = user_input,\n",
        "    chain_type = 'stuff',\n",
        "    vectorstore_kwargs = retriever\n",
        "    )"
      ],
      "metadata": {
        "id": "c1dyOrrxvLAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------"
      ],
      "metadata": {
        "id": "kOVPvYkJ1q_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 꽁수"
      ],
      "metadata": {
        "id": "ZnYj_Pjg1trZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving data to Google Drive"
      ],
      "metadata": {
        "id": "yC1FgBFw2Jqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [PyDrive reference](https://pythonhosted.org/PyDrive/)\n",
        "* [Google Drive API reference](https://developers.google.com/drive/v3/reference/)"
      ],
      "metadata": {
        "id": "nUjHDw1L2NQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': 'Sample file.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# After executing the cell above, a new file named 'Sample file.txt' will appear in your [drive.google.com](https://drive.google.com/) file list."
      ],
      "metadata": {
        "id": "ySBTF69p1yBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing files in Google Drive"
      ],
      "metadata": {
        "id": "A3mSNzgc2Y15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List .txt files in the root.\n",
        "#\n",
        "# Search query reference:\n",
        "# https://developers.google.com/drive/v2/web/search-parameters\n",
        "listed = drive.ListFile({'q': \"title contains '.txt' and 'root' in parents\"}).GetList()\n",
        "for file in listed:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "metadata": {
        "id": "2YG7nE_o2Z3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading files or importing data from Google Drive"
      ],
      "metadata": {
        "id": "JqrZwKL72eSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [PyDrive reference](https://pythonhosted.org/PyDrive/)\n",
        "* [Google Drive API reference](https://developers.google.com/drive/v3/reference/)"
      ],
      "metadata": {
        "id": "s0TSYRZh2mxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = 'REPLACE_WITH_YOUR_FILE_ID'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "metadata": {
        "id": "K21UWBxT2ej3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading files to your local file system"
      ],
      "metadata": {
        "id": "g1ckBSSr2srX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`files.download` will invoke a browser download of the file to your local computer."
      ],
      "metadata": {
        "id": "uBkW3dMa26uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')"
      ],
      "metadata": {
        "id": "NUMElwPu2uOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------"
      ],
      "metadata": {
        "id": "DvZbMgBD1wHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 더 공부할 것"
      ],
      "metadata": {
        "id": "JGbMKmyNvgfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- chain 의 종류 stuff 이외에?\n",
        "chain의 옵션들. return_intermediate_steps?\n",
        "\n",
        "        load_qa_chain  \n",
        "        RetrievalQA  \n",
        "        VectorstoreIndexCreator  \n",
        "        ConversationalRetrievalChain  \n",
        "\n",
        "- chatmemory에 대한 정리\n",
        "\n",
        "- document loader option 정리\n",
        "\n",
        "- local coopilot with lm studio.\n",
        "https://www.toolify.ai/ai-news/build-your-own-coding-copilot-in-vs-code-with-colab-507366\n",
        "\n",
        "- colab with llama.cpp HF\n",
        "https://shiv248.medium.com/hosting-open-source-llm-model-on-google-colaboratory-cc14a42d4053"
      ],
      "metadata": {
        "id": "_syC2v6VvjV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랭체인에서 chain(), chain.run(), chain,invoke()의 차이."
      ],
      "metadata": {
        "id": "SuP7Qf5zwCNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- chain() 과 chain.run()은 거의 같은 기능을 했으나, 지금은 deprecate됨.\n",
        "- 현재는 chain.invoke()를 사용한다. 기능적으로는 별로 달라진거 없다."
      ],
      "metadata": {
        "id": "BKqUnh00wOHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 삽질의 추억"
      ],
      "metadata": {
        "id": "ngAAoKwsvQs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시도1 : 한번에 자료문서를 다 때려 넣으면,\n",
        "- 일단 비싸고 모델에 따라서는 처리가 불가능한 경우가 발생한다."
      ],
      "metadata": {
        "id": "66ur5HREvWQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chain = load_qa_chain(llm = ask_openai(), chain_type='stuff', verbose=True)\n",
        "# user_input = '아내가 먹고 싶은 것은?'\n",
        "# chain.run(input_documents=docs, question=user_input)\n",
        "\n",
        "'''\n",
        "BadRequestError: Error code: 400 - {\n",
        "    'error': {\n",
        "      'message': \"This model's maximum context length is 4097 tokens,\n",
        "      however you requested 11185 tokens (10929 in your prompt; 256 for the completion).\n",
        "      Please reduce your prompt; or completion length.\",\n",
        "      'type': 'invalid_request_error',\n",
        "      'param': None, 'code': None\n",
        "      }\n",
        "      }\n",
        "'''"
      ],
      "metadata": {
        "id": "Y7CaYy1RvPq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}