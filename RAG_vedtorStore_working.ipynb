{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r5KJwOhkl8kQ",
        "3E1bJD9JmGK9",
        "E2EIf0ZLmQ1z",
        "1s1jJQPg87vT",
        "PCFUa6WW8txW",
        "8b7kdtabFR26",
        "l1cb7AL1BCBi",
        "xbfYFb949T60",
        "2qElk4tJu4GJ",
        "JGbMKmyNvgfa",
        "SuP7Qf5zwCNI",
        "ngAAoKwsvQs8",
        "66ur5HREvWQ4"
      ],
      "gpuType": "T4",
      "mount_file_id": "1N5OEjnRU0JrdwiD7269r6JJSFg1xkrfU",
      "authorship_tag": "ABX9TyMfrKIfGUSXvYNj+2NiY1GZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genie0320/langchain/blob/main/RAG_vedtorStore_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting"
      ],
      "metadata": {
        "id": "r5KJwOhkl8kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colab 환경설정\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "os.environ['HF_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "#   f.write('Hello Google Drive!')\n",
        "# !cat '/gdrive/My Drive/foo.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo5Aoy-IyS36",
        "outputId": "cc47b275-9b88-4500-b524-c26ab76dbe59"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "# api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "fC6KTxHBzdtg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_folder = \"/content/drive/MyDrive/data/brand\"\n",
        "SOURCE_folder_id = \"1IW9ywjQHt500b-lEUIxZY69SEI_cB_XS\"\n",
        "SOURCE = \"/content/source/1-1그로스 해킹, 마케팅과 어떻게 다른가요_ - PUBLY.pdf\""
      ],
      "metadata": {
        "id": "UG9uTLxHmqnr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load utills"
      ],
      "metadata": {
        "id": "3E1bJD9JmGK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet icecream"
      ],
      "metadata": {
        "id": "vsqi-QCSmB-z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "from icecream import ic\n",
        "\n",
        "def pp(object):\n",
        "  ppr = pprint.PrettyPrinter(\n",
        "      # indent=40,\n",
        "      width=80\n",
        "      )\n",
        "  return ppr.pprint(object)"
      ],
      "metadata": {
        "id": "U2CeiFFOmAuK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function KeepClicking(){ console.log(\"Clicking\"); document.querySelector(\"colab-connect-button\").click() } setInterval(KeepClicking,60000)"
      ],
      "metadata": {
        "id": "zR142t2zmNji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model setting"
      ],
      "metadata": {
        "id": "E2EIf0ZLmQ1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_sqJeLanmVhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q langchain_openai"
      ],
      "metadata": {
        "id": "_8fs5aIlmsVc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ___ setting ___\n",
        "LLM_MODEL = \"gpt-3.5-turbo\"\n",
        "MAX = 50\n",
        "TEMP = 1.5\n",
        "# _______________\n",
        "\n",
        "from langchain_openai import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_compbot = OpenAI(\n",
        "    temperature=TEMP,\n",
        "    max_tokens = MAX,\n",
        "    verbose = True,\n",
        ")\n",
        "openai_chatbot = ChatOpenAI(\n",
        "    model = LLM_MODEL,\n",
        "    temperature=TEMP,\n",
        "    max_tokens = MAX,\n",
        "    verbose = True,\n",
        ")"
      ],
      "metadata": {
        "id": "_pqU6f5jm3tl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ic(openai_compbot.invoke('hi'))\n",
        "# ic(openai_chatbot.invoke('hi'))"
      ],
      "metadata": {
        "id": "YcmIz_oim9te"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Comletion\n",
        "# prompt = PromptTemplate.from_template( '{time} + \\n\\n text{name} +  {action}')\n",
        "# user_input = 'Where shall we go today?'\n",
        "# new_prompt = prompt.format(\n",
        "#     time = \"old\",\n",
        "#     name = \"Genie\",\n",
        "#     action = user_input\n",
        "# )\n",
        "# res_llm = llm.invoke(new_prompt)\n",
        "\n",
        "# # Chat\n",
        "# template = \"You are my new friend. We met {place} for {activity}.\"\n",
        "# human_template = \"{text}\"\n",
        "# chat_prompt = ChatPromptTemplate.from_messages([\n",
        "#     (\"system\", template), # 값을 tuple로 전달.\n",
        "#     (\"human\", human_template),\n",
        "# ])\n",
        "\n",
        "# prompt = chat_prompt.format_messages(place=\"in library\", activity=\"being a study friend\", text=\"Hey, Sweety!\")\n",
        "# res_chat = chat_model.invoke(prompt).content"
      ],
      "metadata": {
        "id": "ZCBffRk90LQH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(prompt)\n",
        "# print(res_chat)"
      ],
      "metadata": {
        "id": "AQA49rnW0N4o"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG setting"
      ],
      "metadata": {
        "id": "Z5-tmjkAnA24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Components that don't necessarily need GPU:\n",
        "\n",
        "ChromaDB interactions: Most database operations happen on the CPU and don't need GPU acceleration.\n",
        "Vector store: FaissVectorStore operates on CPU by default, and transferring vectors between CPU and GPU might add overhead. Consider the size of your vectors and processing needs before moving the vector store to GPU.\n",
        "\n",
        "`embeddings = AutoEmbeddings.from_pretrained(embedding_model_name).to(\"cuda\")`\n",
        "\n",
        "`retriever = AutoRetriever.from_pretrained(retriever_model_name).to(\"cuda\")`"
      ],
      "metadata": {
        "id": "DZa-KzT_f0JS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SeU0wlIH2XDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loader"
      ],
      "metadata": {
        "id": "tRs6vCVhnE3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- [ ] 웹페이지 로딩\n",
        "- [ ] 옵시디언 로딩\n",
        "- [ ] 노션 로딩\n",
        "- [ ] `from langchain_community.document_loaders import UnstructuredPDFLoader`"
      ],
      "metadata": {
        "id": "UNBYj-_Yiyyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_folder = SOURCE_folder\n",
        "SOURCE_folder_id = SOURCE_folder_id\n",
        "SOURCE = SOURCE"
      ],
      "metadata": {
        "id": "_oRD4j_otisK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_community\n",
        "!pip install -q pypdf"
      ],
      "metadata": {
        "id": "sBFcnWJtnKru"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 파일불러오기"
      ],
      "metadata": {
        "id": "8k-aRhwLBLGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 폴더째로 불러오기"
      ],
      "metadata": {
        "id": "1s1jJQPg87vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] `documents = loader.load()`, `pages = loader.load_and_split()` 의 차이는?"
      ],
      "metadata": {
        "id": "OY9u2bT2FCT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "loader = DirectoryLoader(SOURCE_folder, glob='**/*.pdf', show_progress=True, loader_cls=PyPDFLoader)\n",
        "\n",
        "# documents = loader.load()\n",
        "# print(len(documents), '\\n\\n', documents[0])\n",
        "pages = loader.load_and_split()\n",
        "print(len(pages), '\\n\\n', pages[0])\n",
        "# 위의 둘은 결과적으로 똑같다. 그러나 아래것이 조금 더 빠르다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5clBfisannC2",
        "outputId": "5d291598-0423-4d34-a708-82daa91096ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:04<00:00,  1.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47 \n",
            "\n",
            " page_content=\"24. 2. 12. 오후  5:29 MZ가  주목하는  19 가지  브랜드  인스타그램  부계정  뜯어보기  - PUBLY\\nfile:///C:/Users/GenieEver-2301/Downloads/ 브랜딩 /MZ 가  주목하는  19 가지  브랜드  인스타그램  부계정  뜯어보기  - PUBLY.html 1/23MZ가 주목하는 19가지 브랜드 인스타그램\\n부계정 뜯어보기\\n저자전윤아\\n마케팅 트렌드/실무\\n3,273명이 봤어요 • 79% 만족\\n우리 브랜드를 보여주는 새로운 방법, 인스타그램 부계정\\n💡 10분 안에 이런 걸 알려드려요!\\n세계관 만들기부터 고객 참여까지, 잘나가는 부계정의 5가지 유형 살펴보기\\n우리 계정에 적용해볼 만한 생생한 팁과 풍부한 레퍼런스&인사이트\\n현업 마케터의 코멘트를 통해 살펴보는 인스타그램 부계정 트렌드\\n저자 전윤아\\n교육, AI, 챗봇, 소비재 등 다양한 업종을 거쳐온 콘텐츠 마케터 > 프로필 더 보기\\n디지털 네이티브 MZ, 그들과 좋은 관계를 쌓는 것은 많은 브랜드 마케터의 숙제입니다. MZ는\\n자신이 추구하는 가치에 맞는 것을 찾아 소비하는 걸 즐긴다고들 하죠. 우리 브랜드의 가치를\\n그들의 문법에 맞게 풀어내야 관심과 사랑을 받을 수 있을 거예요.\\n \\nMZ와 가까워지는 정석적인 방법의 하나가 인스타그램 계정 운영입니다. 인스타그램은 MZ의\\n40%가량이 사용하는 가장 친숙한 SNS*거든요. MZ와 소통할 인스타그램 계정을 만들고\\n싶다면, 공식 계정과 별도로 운영하는 부계정을 만들어보면 어떨까요? '회사의 모든 것을 알려야\\n한다'는 사명감 없이 우리 브랜드의 매력을 제대로 드러낼 수 있어요.\\n* KISDI가 2022년 발행한 '세대별 SNS 이용 현황'에 따르면, 밀레니얼과 Gen-Z는 인스타그램을 각각 43.4%, 40.3%\\n사용한다고 해요.\\n \\n이번 아티클에서 MZ의 사랑을 받는 특색 있는 부계정을 한눈에 살펴보세요. 인스타그램 마케팅\\n하면 바로 떠오르는 유명한 계정부터 아이디어가 참신한 계정까지, 총 19개 계정을 5가지\\n유형으로 나눠 정리했어요. 우리 회사 인스타그램 부계정 운영에 바로 참고할 수 있을 거예요.\\n \\n✅ 단, 본계정과 부계정을 나눠 운영하지 않는 경우에도 부계정 운영에 영감을 줄 경우 함께\\n소개합니다. (ex. 독자적인 세계관으로 유명한 빙그레 등)\\n[Ctrl·Cmd+F]로 원하는 사례를 찾아서 빠르게 읽어보세요!\\n세계관 창조형 → #빙그레  #이마트24  #풀무원  #오롤리데이\\n유료 콘텐츠를\\n무료로\\n공유해 보세요.\\n5,000P 적립\" metadata={'source': '/content/drive/MyDrive/data/brand/MZ가 주목하는 19가지 브랜드 인스타그램 부계정 뜯어보기 - PUBLY.pdf', 'page': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 파일 하나 불러오기"
      ],
      "metadata": {
        "id": "PCFUa6WW8txW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이건 PDF\n",
        "# from langchain_community.document_loaders import PyPDFLoader\n",
        "# loader = PyPDFLoader(SOURCE)\n",
        "# pages = loader.load_and_split()\n",
        "# print(len(pages), '\\n\\n', pages[0])"
      ],
      "metadata": {
        "id": "ZNgeIrFHnVP_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이건 뭔...지\n",
        "# with open(\"../../state_of_the_union.txt\") as f: # 이건 로컬파일일 때...이야기인가. loader와 무슨 관계?\n",
        "#     state_of_the_union = f.read()"
      ],
      "metadata": {
        "id": "_s7ke_fPnaAq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WORD 파일"
      ],
      "metadata": {
        "id": "8b7kdtabFR26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Docx2TextLoader\n",
        "# CSVLoader : 이건 좀 사용법이 다르다."
      ],
      "metadata": {
        "id": "uoUQ26fAFVNV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### html 불러오기"
      ],
      "metadata": {
        "id": "xamCUBZq-Ajh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TARGET_URL = 'https://blog.ab180.co/posts/growth-hacking-5-features'\n",
        "# TARGET_URLS = [\n",
        "#     'https://blog.ab180.co/posts/growth-hacking-5-features',\n",
        "#     'https://dbr.donga.com/article/view/1202/article_no/9026/ac/magazine',\n",
        "#     'https://blog.hsad.co.kr/3323',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%eb%a7%88%ec%bc%80%ed%8c%85%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83/',\n",
        "#     'https://groobee.net/blog/%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4%EB%A5%BC-%EC%9C%84%ED%95%9C-%ED%95%B5%EC%8B%AC-%EC%A0%84%EB%9E%B5-%EA%B7%B8%EB%A1%9C%EC%8A%A4-%ED%95%B4%ED%82%B9%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B2%83-2/',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%ed%95%b4%ed%82%b9%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83-3/',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%ed%95%b4%ed%82%b9%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83-4/',\n",
        "#     'https://groobee.net/blog/%eb%b9%84%ec%a6%88%eb%8b%88%ec%8a%a4%eb%a5%bc-%ec%9c%84%ed%95%9c-%ed%95%b5%ec%8b%ac-%ec%a0%84%eb%9e%b5-%ea%b7%b8%eb%a1%9c%ec%8a%a4-%ed%95%b4%ed%82%b9%ec%9d%98-%eb%aa%a8%eb%93%a0-%ea%b2%83-5/',\n",
        "#     'https://groobee.net/blog/%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4%EB%A5%BC-%EC%9C%84%ED%95%9C-%ED%95%B5%EC%8B%AC-%EC%A0%84%EB%9E%B5-%EA%B7%B8%EB%A1%9C%EC%8A%A4-%ED%95%B4%ED%82%B9%EC%9D%98-%EB%AA%A8%EB%93%A0-%EA%B2%83-6/'\n",
        "# ]"
      ],
      "metadata": {
        "id": "ucbMZfDW-N26"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 로컬에 있는 html 불러오기"
      ],
      "metadata": {
        "id": "XbYK0J5GrCII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실패함..."
      ],
      "metadata": {
        "id": "WBxIb1UTrABm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 웹에서 한페이지 불러오기"
      ],
      "metadata": {
        "id": "l1cb7AL1BCBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import WebBaseLoader\n",
        "# loader = WebBaseLoader(TARGET_URL)\n",
        "\n",
        "# web_data = loader.load()\n",
        "# print(len(web_data), '\\n', web_data[0])"
      ],
      "metadata": {
        "id": "m5EIhdp2-Crj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 웹에서 여러페이지 불러오기"
      ],
      "metadata": {
        "id": "-ZJae6lfA_9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "한번에 많이 가져올 수 있어서 좋으나... 결과물이 좀 더럽다."
      ],
      "metadata": {
        "id": "FQgHzt20EJOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q unstructured"
      ],
      "metadata": {
        "id": "wRoY0PixDD42"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import UnstructuredURLLoader\n",
        "# loader = UnstructuredURLLoader(urls = TARGET_URLS)\n",
        "# web_datas = loader.load()"
      ],
      "metadata": {
        "id": "7u566kHFA5bG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(web_datas), '\\n', web_datas[0])"
      ],
      "metadata": {
        "id": "Pw6qXnzkDUhV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### how to use bs4."
      ],
      "metadata": {
        "id": "HyAFK2H9ar_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.document_loaders import UnstructuredURLLoader\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# def extract_contents_by_tag(html_document, tag_name):\n",
        "#     soup = BeautifulSoup(html_document, \"html.parser\")\n",
        "\n",
        "#     tag = soup.find(tag_name)\n",
        "\n",
        "#     if tag is not None:\n",
        "#         return tag.text\n",
        "#     else:\n",
        "#         return None\n",
        "\n",
        "# # Load the HTML documents from the URLs\n",
        "# loader = UnstructuredURLLoader(urls=TARGET_URLS)\n",
        "# web_datas = loader.load()\n",
        "\n",
        "# # Extract the contents only inside of the <h1> tag\n",
        "# h1_contents = []\n",
        "# for web_data in web_datas:\n",
        "#     h1_contents.append(extract_contents_by_tag(web_data.page_content, \"h1\"))\n",
        "\n",
        "# # Print the extracted contents\n",
        "# print(h1_contents)"
      ],
      "metadata": {
        "id": "SeB8OsvTaX1T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 모양 살펴보기"
      ],
      "metadata": {
        "id": "hKiDDyER81eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pages = web_datas\n",
        "\n",
        "for p in pages[0:10]:\n",
        "    with open('/content/drive/MyDrive/foo.txt', 'a') as f:\n",
        "        f.write(p.page_content)\n",
        "\n",
        "!head -n 10 '/content/drive/MyDrive/foo.txt'"
      ],
      "metadata": {
        "id": "FF2zEOc46FQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c487fc11-68cc-41cf-f0a7-062aeade75fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24. 2. 12. 오후  5:29 MZ가  주목하는  19 가지  브랜드  인스타그램  부계정  뜯어보기  - PUBLY\n",
            "file:///C:/Users/GenieEver-2301/Downloads/ 브랜딩 /MZ 가  주목하는  19 가지  브랜드  인스타그램  부계정  뜯어보기  - PUBLY.html 1/23MZ가 주목하는 19가지 브랜드 인스타그램\n",
            "부계정 뜯어보기\n",
            "저자전윤아\n",
            "마케팅 트렌드/실무\n",
            "3,273명이 봤어요 • 79% 만족\n",
            "우리 브랜드를 보여주는 새로운 방법, 인스타그램 부계정\n",
            "💡 10분 안에 이런 걸 알려드려요!\n",
            "세계관 만들기부터 고객 참여까지, 잘나가는 부계정의 5가지 유형 살펴보기\n",
            "우리 계정에 적용해볼 만한 생생한 팁과 풍부한 레퍼런스&인사이트\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all the content.\n",
        "# !cat '/content/drive/MyDrive/foo.txt'"
      ],
      "metadata": {
        "id": "15S_NnvSYdB0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 줄바꿈등 제거하기"
      ],
      "metadata": {
        "id": "xbfYFb949T60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: 줄바꿈 등을 제거한 후"
      ],
      "metadata": {
        "id": "FgA0t_7ctx04"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitter"
      ],
      "metadata": {
        "id": "gxJaLocungLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] `# from langchain_experimental.text_splitter import SemanticChunker > 이건 openai의 실험적 기능이라는데... 한번 써보고 싶음.`"
      ],
      "metadata": {
        "id": "wq1tHm1KoqIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain_core langchain_community\n",
        "# !pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "L-o03gp2mWMX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 글자수로 맞춰 분할."
      ],
      "metadata": {
        "id": "lf0L3sqTc7k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # loader : pages\n",
        "\n",
        "# from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# text_splitter = CharacterTextSplitter(\n",
        "#     # separator = '\\n\\n',\n",
        "#     chunk_size = 1000,\n",
        "#     chunk_overlap = 100,\n",
        "#     length_function= len # 이 경우, 단순히 글자수를 기준으로 1000을 세라는 것.\n",
        "# )\n",
        "\n",
        "# chunks = text_splitter.split_documents(pages) # 얘는 배열 그대로를 처리할 수 있다.\n",
        "# # texts= text_splitter.split_text(pages) # 얘는 str이어야 함.\n",
        "# chunks[0]"
      ],
      "metadata": {
        "id": "dfcHoyNTno6q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(chunks)"
      ],
      "metadata": {
        "id": "3tzytleGHadL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lens = []\n",
        "# for n in chunks:\n",
        "#     lens.append(len(n.page_content))\n",
        "# print(sorted(lens, reverse=True))"
      ],
      "metadata": {
        "id": "emZSLk3BHxBS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 재귀적으로 분할"
      ],
      "metadata": {
        "id": "8uVyBkSvc3od"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "... 그러나.... 캐릭터 스플리터에서 구분자는 \\n\\n로 주었을 때와 결과가 같다. 왜 쓰는지."
      ],
      "metadata": {
        "id": "m3z985CWfMWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 적정한 길이로 잘라주고\n",
        "rc_splitter = RecursiveCharacterTextSplitter(\n",
        "    # separator=\"\\n\\n\",  #이 옵션은 의미가 없다. 알아서 맞춰서 잘라준다.\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "docs = []\n",
        "for document in pages:\n",
        "    docs.append(document.page_content)\n",
        "\n",
        "# texts = splitter.split_documents(pages) # 단순 커터\n",
        "rc_chunks = rc_splitter.create_documents(docs) # 옵션을 줄 수 있다. []을 받는다.\n",
        "\n",
        "\n",
        "len(rc_chunks)"
      ],
      "metadata": {
        "id": "ZOQMre6sIWDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d988499-5dde-4e8a-af53-377eaba08c1a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token 길이에 맞춰 분할"
      ],
      "metadata": {
        "id": "4syk8Xtjcw_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tiktoken"
      ],
      "metadata": {
        "id": "0O7QniQwSE3Q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# token 단위로 분할하는 기능\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base') # openai에서 사용하는 규약이라고 함.\n",
        "\n",
        "# 해당 텍스트를 처리하기 위한 token의 수를 세는 함수\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    return len(tokens)\n",
        "\n",
        "tiktoken_len(pages[0].page_content)\n",
        "\n",
        "# rc_t_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder( > 이런 것도 있다던데.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "rc_t_splitter = RecursiveCharacterTextSplitter(\n",
        "    is_separator_regex=False,\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=tiktoken_len,# 얘는 토큰길이에 따름.\n",
        ")\n",
        "\n",
        "tk_chunks = rc_t_splitter.split_documents(pages)\n",
        "len(tk_chunks)\n",
        "tk_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04oDXfxZG2uU",
        "outputId": "107eb2e5-8029-4fd8-d74c-67e47de61c35"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"24. 2. 12. 오후  5:29 MZ가  주목하는  19 가지  브랜드  인스타그램  부계정  뜯어보기  - PUBLY\\nfile:///C:/Users/GenieEver-2301/Downloads/ 브랜딩 /MZ 가  주목하는  19 가지  브랜드  인스타그램  부계정  뜯어보기  - PUBLY.html 1/23MZ가 주목하는 19가지 브랜드 인스타그램\\n부계정 뜯어보기\\n저자전윤아\\n마케팅 트렌드/실무\\n3,273명이 봤어요 • 79% 만족\\n우리 브랜드를 보여주는 새로운 방법, 인스타그램 부계정\\n💡 10분 안에 이런 걸 알려드려요!\\n세계관 만들기부터 고객 참여까지, 잘나가는 부계정의 5가지 유형 살펴보기\\n우리 계정에 적용해볼 만한 생생한 팁과 풍부한 레퍼런스&인사이트\\n현업 마케터의 코멘트를 통해 살펴보는 인스타그램 부계정 트렌드\\n저자 전윤아\\n교육, AI, 챗봇, 소비재 등 다양한 업종을 거쳐온 콘텐츠 마케터 > 프로필 더 보기\\n디지털 네이티브 MZ, 그들과 좋은 관계를 쌓는 것은 많은 브랜드 마케터의 숙제입니다. MZ는\\n자신이 추구하는 가치에 맞는 것을 찾아 소비하는 걸 즐긴다고들 하죠. 우리 브랜드의 가치를\\n그들의 문법에 맞게 풀어내야 관심과 사랑을 받을 수 있을 거예요.\\n \\nMZ와 가까워지는 정석적인 방법의 하나가 인스타그램 계정 운영입니다. 인스타그램은 MZ의\\n40%가량이 사용하는 가장 친숙한 SNS*거든요. MZ와 소통할 인스타그램 계정을 만들고\\n싶다면, 공식 계정과 별도로 운영하는 부계정을 만들어보면 어떨까요? '회사의 모든 것을 알려야\\n한다'는 사명감 없이 우리 브랜드의 매력을 제대로 드러낼 수 있어요.\\n* KISDI가 2022년 발행한 '세대별 SNS 이용 현황'에 따르면, 밀레니얼과 Gen-Z는 인스타그램을 각각 43.4%, 40.3%\\n사용한다고 해요.\\n \\n이번 아티클에서 MZ의 사랑을 받는 특색 있는 부계정을 한눈에 살펴보세요. 인스타그램 마케팅\\n하면 바로 떠오르는 유명한 계정부터 아이디어가 참신한 계정까지, 총 19개 계정을 5가지\", metadata={'source': '/content/drive/MyDrive/data/brand/MZ가 주목하는 19가지 브랜드 인스타그램 부계정 뜯어보기 - PUBLY.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [TODO] 나만의 메타데이터 삽입"
      ],
      "metadata": {
        "id": "uaV_OTN2xVC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RecursiveCharacterTextSplitter 에 나만의 메타데이터를 주입하는 방법\n",
        "# class MyRecursiveCharacterTextSplitter(RecursiveCharacterTextSplitter):\n",
        "#     def _get_metadata_from_document(self, document):\n",
        "#         # Extract the default metadata\n",
        "#         metadata = super()._get_metadata_from_document(document)\n",
        "\n",
        "#         # Add additional metadata\n",
        "#         metadata[\"custom_field_1\"] = \"value_1\"\n",
        "#         metadata[\"custom_field_2\"] = \"value_2\"\n",
        "\n",
        "#         return metadata"
      ],
      "metadata": {
        "id": "XLSth1xMw-QE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tk_lens = []\n",
        "# for n in tk_chunks:\n",
        "#     tk_lens.append(len(n.page_content))\n",
        "# print(sorted(tk_lens, reverse=True))"
      ],
      "metadata": {
        "id": "Q3KErhl6b-Cz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # tk_chunks[0].metadata['source']\n",
        "# keys = []\n",
        "# for chunk in tk_chunks:\n",
        "#     keys.append(chunk.metadata['source'])\n",
        "\n",
        "# ic(len(keys))\n",
        "# fils_in_db = set(keys.copy())\n",
        "# fils_in_db"
      ],
      "metadata": {
        "id": "jItU1IKLs_ni"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding / Saving"
      ],
      "metadata": {
        "id": "zDjBlW-GouwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "허깅페이스 'jhgan/ko-sbert-nli' 라는 모델을 이용해서 한국어 임베딩을 해보자.\n",
        "https://youtu.be/qH69XGQZHDg?si=inQxWCOsugwJmcSo\n",
        "\n",
        "임베딩은 문장을 숫자로 저장해준다. 서로간의 관계성에 따라 숫자가 커지거나 작게 저장이 되는 것. 이렇게 계산되어 산출한 숫자들을 그 모습대로 저장하는 것이 저장소다. 벡터저장소는 이렇게 산출된 숫자들을, 그 숫자에 따라 지그지그 모양으로 저장한다. 따라서... 임베딩계산은 임베딩때 하지만, 그걸 기준으로 인덱싱하는 건 저장소의 기능인 것이다."
      ],
      "metadata": {
        "id": "nkZVtFICIofH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB_URL = '/content/drive/MyDrive/vector_chrm/'\n",
        "DB_KO_URL = '/content/drive/MyDrive/vector_ko_chroma/'\n",
        "texts = tk_chunks"
      ],
      "metadata": {
        "id": "3zSmXSSh4HrB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chroma_client = chromadb.Client() > 이건 뭐에 필요한 것인지..."
      ],
      "metadata": {
        "id": "LNZVPioBqrSX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q chromadb\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "openai_embed = OpenAIEmbeddings()\n",
        "# vector_stores = Chroma.from_documents(texts, openai_embed)\n",
        "# vector_stores = Chroma.from_documents(\n",
        "#     texts,\n",
        "#     openai_embed,\n",
        "#     persist_directory = DB_URL\n",
        "# )\n",
        "print('openai_embed : Document Stored!!')\n",
        "print(openai_embed)"
      ],
      "metadata": {
        "id": "7bml4DpTn-kO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8869576-81b9-407d-b687-c3e7725efe61"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openai_embed : Document Stored!!\n",
            "client=<openai.resources.embeddings.Embeddings object at 0x7e86013bf220> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7e8601895630> model='text-embedding-ada-002' dimensions=None deployment='text-embedding-ada-002' openai_api_version='' openai_api_base=None openai_api_type='' openai_proxy='' embedding_ctx_length=8191 openai_api_key='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' openai_organization=None allowed_special=set() disallowed_special='all' chunk_size=1000 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(DB_URL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3cKYNgXEFPM",
        "outputId": "3554ed63-3a7c-4b2a-ff61-12f190576a6a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/vector_chrm/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q sentence-transformers chromadb\n",
        "# from langchain_community.vectorstores import Chroma\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "# hug_embed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# # vector_stores = Chroma.from_documents(texts, hug_embed)\n",
        "# vector_stores = Chroma.from_documents(\n",
        "#     texts,\n",
        "#     hug_embed,\n",
        "#     persist_directory = DB_URL\n",
        "# )\n",
        "# print('hug_embed : Document Stored!!')"
      ],
      "metadata": {
        "id": "LZ-dw9wso_9V"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q sentence-transformers chromadb\n",
        "# from langchain_community.vectorstores import Chroma\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# ko_embed = HuggingFaceEmbeddings(\n",
        "#     model_name=\"jhgan/ko-sbert-nli\",\n",
        "#     model_kwargs={'device' : 'cpu'}\n",
        "#     encode_kwargs={'normalize_embeddings':True}\n",
        "#     )\n",
        "# # vector_stores = Chroma.from_documents(texts, hug_embed)\n",
        "# vector_stores = Chroma.from_documents(\n",
        "#     texts,\n",
        "#     ko_embed,\n",
        "#     persist_directory = DB_KO_URL\n",
        "# )\n",
        "# print('hug_embed : Document Stored!!')"
      ],
      "metadata": {
        "id": "knhr45nfKbA2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------"
      ],
      "metadata": {
        "id": "ZKZ21_KvtFHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding model test"
      ],
      "metadata": {
        "id": "r4GC30qqFvix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings_test = hug_embed.embed_documents(\n",
        "#     [\n",
        "#         '안녕하세요',\n",
        "#         '제 이름은 홍길동입니다.',\n",
        "#         '이름이 무엇인가요',\n",
        "#         '랭체인은 유용합니다',\n",
        "#         'Hello world',\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# len(embeddings_test), len(embeddings_test[0])"
      ],
      "metadata": {
        "id": "ApmFbrLN7Aox"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_query_q = hug_embed.embed_query('이 대화에서 언급된 이름은 무엇입니까?')\n",
        "# test_query_a = hug_embed.embed_query('이 대화에서 언급된 이름은 홍길동입니다')\n",
        "# print(len(test_query_q), len(test_query_a))"
      ],
      "metadata": {
        "id": "i_N4Etnm7uYd"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # !pip install numpy\n",
        "# from numpy import dot\n",
        "# # from numpy.linaig import norm\n",
        "# from numpy import linalg as LA\n",
        "# import numpy as np\n",
        "\n",
        "# def cos_sim(A,B):\n",
        "#     # return dot(A,B)/(norm(A)+norm(B))\n",
        "#     return dot(A,B)/(LA.norm(A)+LA.norm(B))"
      ],
      "metadata": {
        "id": "i8jEo6_C8bRj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(cos_sim(test_query_q, test_query_a))\n",
        "# print(cos_sim(test_query_q, embeddings_test[1]))\n",
        "# print(cos_sim(test_query_a, embeddings_test[2]))"
      ],
      "metadata": {
        "id": "D4Aq0Xq78Hl-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jVum-LKHreM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = openai_embed\n",
        "# ic(openai_compbot.invoke('hi'))\n",
        "# ic(openai_chatbot.invoke('hi'))"
      ],
      "metadata": {
        "id": "d-CByZlpkqlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e182481-d928-4d24-d256-1c74ab189ef8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| openai_compbot.invoke('hi'): (' continents Emily chose groups of sentences for the video\".And at last, '\n",
            "                                  'their retrobucks special caxis vice checker rode text away different '\n",
            "                                  'likewise which approved net of happiest textiles widest clean to $\"{}\").\n",
            "                                 '\n",
            "                                  'What can really make Asians Gins together?” Shares choosing diver')\n",
            "ic| openai_chatbot.invoke('hi'): AIMessage(content='Hello! How can I assist you today?')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chroma"
      ],
      "metadata": {
        "id": "qfZDemE88iv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chroma 객체 설정. 컬렉션 만들기, 데이터 관리하기\n",
        "> 메타데이터 추가해서 중복관리하기!!!"
      ],
      "metadata": {
        "id": "I4S8ieFKNIAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그리고 retreiver를 만들어서\n",
        "# from langchain.chains import RetrievalQA\n",
        "\n",
        "# from_db = Chroma(persist_directory=DB_URL, embedding_function=embedding)\n",
        "# retriever = from_db.as_retriever(search_type = 'similarity', search_kwargs={'k' :2})"
      ],
      "metadata": {
        "id": "XSaXs3XHuZzA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Retrieve from DB\n",
        "# !pip install -q chromadb\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "openai_embed = OpenAIEmbeddings()\n",
        "load_vector_store = Chroma(\n",
        "    persist_directory = DB_URL,\n",
        "    embedding_function = embeddings,\n",
        "    )"
      ],
      "metadata": {
        "id": "dkbQ4J7EsQeN"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retriever = load_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "# docs = load_vector_store.similarity_search(query)\n",
        "# docs = retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "j5gHt2PYpL1d"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = '네이밍의 본질은 무엇인가'\n",
        "docs = load_vector_store.similarity_search_with_relevance_scores(query, k=6)\n",
        "docs[0][0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "yo7LchD_1_YO",
        "outputId": "64e6b5d5-d17a-41fc-97f5-0e6967294d14"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'이 가이드북을 통해 서비스의 정체성에 맞는 브랜드명을 고민해보세요. 좋은 네이밍과 성공적인\\n비즈니스가 함께하기를 진심으로 기원합니다.\\n👀 바쁘다면 이거라도!\\n네이밍의 본질은 모객. 모객에 도움 되지 않는 네임은 좋지 않은 네임.\\n커뮤니케이션 비용이 적게 드는 브랜드명이 좋은 브랜드명.\\n키워드를 도출해 주는 세 가지 질문\\n1) 제품 혹은 서비스를 경험할 때 고객의 행동을 순차적으로 나열\\n2) 제품/서비스를 경험할 때 고객의 생각과 감정을 나열\\n3) 고객이 느낄 수 있는 다른 제품/서비스와의 차별점을 대표자의 입장에서\\n나열\\n1)~3)에서 반복되는 키워드를 추출. 이 키워드의 조합이 키컨셉'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [FIX] 가져온 데이터 중에서 중복데이터 삭제."
      ],
      "metadata": {
        "id": "lk_G3phY6tkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ic(len(docs))\n",
        "filterd_docs = []\n",
        "\n",
        "# Delete duplicate datas in docs\n",
        "for index, element in enumerate(docs):\n",
        "    # print(f\"Index: {index}, Element: {element}\")\n",
        "    if index%2 == 0:\n",
        "        filterd_docs.append(element)\n",
        "\n",
        "ic(len(filterd_docs))\n",
        "\n",
        "print('\\n가장 유사한 문서 :\\n {}\\n'.format(filterd_docs[0][0].page_content))\n",
        "print('가장 유사한 문서의 유사도 :\\n {}'.format(filterd_docs[0][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjhkpNzVof4B",
        "outputId": "cff40522-34db-4841-b894-101cfad505fa"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| len(docs): 6\n",
            "ic| len(filterd_docs): 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "가장 유사한 문서 :\n",
            " 이 가이드북을 통해 서비스의 정체성에 맞는 브랜드명을 고민해보세요. 좋은 네이밍과 성공적인\n",
            "비즈니스가 함께하기를 진심으로 기원합니다.\n",
            "👀 바쁘다면 이거라도!\n",
            "네이밍의 본질은 모객. 모객에 도움 되지 않는 네임은 좋지 않은 네임.\n",
            "커뮤니케이션 비용이 적게 드는 브랜드명이 좋은 브랜드명.\n",
            "키워드를 도출해 주는 세 가지 질문\n",
            "1) 제품 혹은 서비스를 경험할 때 고객의 행동을 순차적으로 나열\n",
            "2) 제품/서비스를 경험할 때 고객의 생각과 감정을 나열\n",
            "3) 고객이 느낄 수 있는 다른 제품/서비스와의 차별점을 대표자의 입장에서\n",
            "나열\n",
            "1)~3)에서 반복되는 키워드를 추출. 이 키워드의 조합이 키컨셉\n",
            "\n",
            "가장 유사한 문서의 유사도 :\n",
            " 0.7736606377843839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FAISS"
      ],
      "metadata": {
        "id": "8bJEGrtU8dh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chroma는 db라고 하는데, Faiss는 유사성검색 및 클러스터링을 위한 '라이브러리'라고 한다.\n",
        "\n",
        "- 벡터집합에서 검색하는 알고리즘이 포함되어 있으며,\n",
        "- RAM에 맞지 않는 벡터까지 검색한다고 한다.\n",
        "- 매개변수 조정을 위한 코드도 포함되어 있다"
      ],
      "metadata": {
        "id": "V36m4ggy8wtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "Uh5vAy-o9IfC"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "texts = tk_chunks\n",
        "DB_KO_FAISS = '/content/drive/MyDrive/vector_ko_faiss/'\n",
        "\n",
        "ko_embed = HuggingFaceEmbeddings(\n",
        "    model_name=\"jhgan/ko-sbert-nli\",\n",
        "    model_kwargs={'device' : 'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings':True}\n",
        "    )"
      ],
      "metadata": {
        "id": "LO04zUzX9avk"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# faiss_stores = FAISS.from_documents(\n",
        "#     texts,\n",
        "#     ko_embed,\n",
        "#     # persist_directory = DB_KO_FAISS\n",
        "# )\n",
        "# faiss_stores.save_local(DB_KO_FAISS)\n",
        "# print('hug_embed : Document Stored!!')\n",
        "\n",
        "load_faiss = FAISS.load_local(DB_KO_FAISS, ko_embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4JikilICUPk",
        "outputId": "673d3001-92d6-4869-9138-aad1ed652d15"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hug_embed : Document Stored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = '네이밍의 본질은 무엇인가'\n",
        "docs_faiss = load_faiss.similarity_search_with_score(query, k=3) # 점수가 낮을수록 유사\n",
        "# docs_faiss = load_faiss.similarity_search_with_relevance_scores(query, k=6) # 점수가 높을 수록 유사\n",
        "\n",
        "# 결과에 다양성을 줄 수 있다. 아래는 총 20의 관련문서 중, 다양성을 고려하여 3개를 반환하되, 그 사이의 균형점은 0.3정도로 한다...는 뜻.\n",
        "docs_faiss_max = load_faiss.max_marginal_relevance_search(query, fetch_k=20, lambda_mult=0.3, k=3)\n",
        "\n",
        "for d in docs_faiss:\n",
        "    print (f'문서 유사도 : {round(d[1],2)} \\n {d[0].metadata}\\n')\n",
        "    # print (d[0].page_content,'\\n')\n",
        "    print (\"-\"*100)\n",
        "\n",
        "print (\"*-*\"*100)\n",
        "\n",
        "# for d in docs_faiss_max:\n",
        "#     print (f'문서 유사도 : {round(d[1],2)} \\n {d[0].metadata}\\n')\n",
        "#     # print (d[0].page_content,'\\n')\n",
        "#     print (\"-\"*100)\n",
        "\n",
        "# docs_faiss_max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mKggQIW9IW8",
        "outputId": "6198ab19-9287-43ab-fdb8-e1190e8a9a7b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문서 유사도 : 0.6600000262260437 \n",
            " {'source': '/content/drive/MyDrive/data/brand/광고비 줄여주는 브랜드명, 가게명, 회사명 네이밍 방법(네이밍 작업 템플릿 제공) - PUBLY.pdf', 'page': 9}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "문서 유사도 : 0.7300000190734863 \n",
            " {'source': '/content/drive/MyDrive/data/brand/광고비 줄여주는 브랜드명, 가게명, 회사명 네이밍 방법(네이밍 작업 템플릿 제공) - PUBLY.pdf', 'page': 4}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "문서 유사도 : 0.7599999904632568 \n",
            " {'source': '/content/drive/MyDrive/data/brand/광고비 줄여주는 브랜드명, 가게명, 회사명 네이밍 방법(네이밍 작업 템플릿 제공) - PUBLY.pdf', 'page': 1}\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "*-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-*\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='이 가이드북을 통해 서비스의 정체성에 맞는 브랜드명을 고민해보세요. 좋은 네이밍과 성공적인\\n비즈니스가 함께하기를 진심으로 기원합니다.\\n👀 바쁘다면 이거라도!\\n네이밍의 본질은 모객. 모객에 도움 되지 않는 네임은 좋지 않은 네임.\\n커뮤니케이션 비용이 적게 드는 브랜드명이 좋은 브랜드명.\\n키워드를 도출해 주는 세 가지 질문\\n1) 제품 혹은 서비스를 경험할 때 고객의 행동을 순차적으로 나열\\n2) 제품/서비스를 경험할 때 고객의 생각과 감정을 나열\\n3) 고객이 느낄 수 있는 다른 제품/서비스와의 차별점을 대표자의 입장에서\\n나열\\n1)~3)에서 반복되는 키워드를 추출. 이 키워드의 조합이 키컨셉', metadata={'source': '/content/drive/MyDrive/data/brand/광고비 줄여주는 브랜드명, 가게명, 회사명 네이밍 방법(네이밍 작업 템플릿 제공) - PUBLY.pdf', 'page': 9}),\n",
              " Document(page_content='비주얼적으로 신경을 많이 쓴 이미지는 브랜드에서 제작한 광고 소재 느낌이 바로 들기 때문일\\n거예요. \\n \\n일상적이고 자연스러운 이미지들의 경우 광고 이미지인지 일반 사용자들이 게시한 이미지인지\\n구분하기가 어렵기도 하고, 좀 더 SNS 플랫폼의 톤 앤 매너와 닮은 친근함이 느껴져 광고에 대한\\n거부감이 낮게 형성돼요.', metadata={'source': '/content/drive/MyDrive/data/brand/구매를 부르는 뷰티 브랜드의 비주얼 기획 노하우 (feat. 제품 촬영팁) - PUBLY.pdf', 'page': 8}),\n",
              " Document(page_content=\"24. 2. 12. 오후  5:30 구매를  부르는  뷰티  브랜드의  비주얼  기획  노하우  (feat. 제품  촬영팁 ) - PUBLY\\nfile:///C:/Users/GenieEver-2301/Downloads/ 브랜딩 / 구매를  부르는  뷰티  브랜드의  비주얼  기획  노하우  (feat. 제품  촬영팁 ) - PUBLY.html 4/13출처:\\n제형 활용: <아로마티카 바디워시>, <VDL 파운데이션>\\n성분 소품 활용: <AGE20'S 선크림>, <이든미네랄 프라이머>, <큐어 젤리 크림>\\n몇 가지 예시를 보여드리겠습니다. 촉촉함과 밀착력을 강조하고 싶은 쿠션이나 파운데이션\\n제품의 경우 제형에서 이러한 장점이 드러날 수 있도록 하는 이미지나 영상 콘텐츠를\\n만들어야겠죠?\\n제품을 사용해 메이크업한 모델의 피부에서 윤광이 나는 점으로 표현할 수도 있겠지만, 요즘\\n소비자들은 고정된 사진에서는 보정이 어느 정도 들어갔다 생각하는 경향이 있어요. 그래서\\n움직이는 영상 및 GIF를 활용해 제형을 보여주는 것을 추천드립니다.\\n©CJ OliveYoung 웨이크메이크 상세페이지\\n또한, 끈적임이 없는 선케어 제품력을 보여줘야 한다면 제품을 바른 부위에 깃털이나, 기름종이,\\n스티로폼 등의 소품들을  활용해 우리 제품이 산뜻하게 마무리된다는 점을 보여줄 수 있는 영상\\n소재들을 제작해보는 방향도 많이들 시도하고 있습니다.\\n©CJ OliveYoung 식물나라 상세페이지\\n여러 컬러들로 구성된 섀도 팔레트를 출시했다면, 우리 제품의 색 조합을 활용해 어떻게 매력적인\\n룩을 연출할 수 있을지 등을 모델을 활용해 비주얼 콘텐츠를 만든다면, 소비자들의 구매욕을\\n자극시킬 수 있을 거예요.\\n©CJ OliveYoung 릴리바이레드 상세페이지\", metadata={'source': '/content/drive/MyDrive/data/brand/구매를 부르는 뷰티 브랜드의 비주얼 기획 노하우 (feat. 제품 촬영팁) - PUBLY.pdf', 'page': 3})]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval"
      ],
      "metadata": {
        "id": "aPKdQ_GaNd-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input_multiquery = input('검색할 키워드 입력 :')\n",
        "# question = user_input_multiquery\n",
        "# llm = openai_chatbot\n",
        "\n",
        "# retriever_from_llm = MultiQueryRetriever.from_llm(\n",
        "#     retriever=load_vector_store.as_retriever(), llm=llm\n",
        "# )\n",
        "# # print(retriever_from_llm)\n",
        "# # print(len(res))\n",
        "# res = retriever_from_llm.get_relevant_documents(query = query)"
      ],
      "metadata": {
        "id": "_pUb2xu5sVkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = []\n",
        "for d in docs:\n",
        "    context.append(d.page_content)\n",
        "context"
      ],
      "metadata": {
        "id": "4XyNZGtqug2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making QA chain"
      ],
      "metadata": {
        "id": "a2DkROL9usnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "# RAG 체인을 만들고\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=ask_openai(), chain_type='stuff', retriever = retriever, return_source_documents=True\n",
        ")\n",
        "\n",
        "# 질문을 하면 된다.\n",
        "rerult = qa({'query': user_input})\n",
        "\n",
        "# print results\n",
        "rerult"
      ],
      "metadata": {
        "id": "BbyWl617ur-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Answer"
      ],
      "metadata": {
        "id": "QiliGhS5s01U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Make answer with LLM\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "user_input_multiquery = input('검색할 키워드 입력 :')\n",
        "question = user_input_multiquery\n",
        "llm = chat_model\n",
        "qa_chain = RetrievalQA.from_chain_type(llm, retriever=db.as_retriever())\n",
        "result = qa_chain.invoke({'query':question})\n",
        "# print(result)\n",
        "print(result['result'])"
      ],
      "metadata": {
        "id": "06qpWy54s8qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "lNgoix8bkBWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template('''\n",
        "Use following context to answer the user's question in Korean.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "---------------------\n",
        "Context :{context_str}\n",
        "---------------------\n",
        "\n",
        "Question: {query_str}\n",
        "\n",
        "Only return the helpful answer below and nothing else.\n",
        "Answer:\n",
        "''')"
      ],
      "metadata": {
        "id": "NMp7XeTNkzx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"팀장과 팀원의 차이는?\""
      ],
      "metadata": {
        "id": "chLQmY2p8Vll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = prompt_template.format(\n",
        "#     context_str = context,\n",
        "#     query_str = question\n",
        "#     )"
      ],
      "metadata": {
        "id": "UCtL9S4xlNop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"google/flan-t5-xxl\"\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,\n",
        "    repo_id = repo_id,\n",
        "    model_kwargs = {'temperature':0.3, \"max_length\" : 500}\n",
        ")"
      ],
      "metadata": {
        "id": "eDNmjQvnyEEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchainhub"
      ],
      "metadata": {
        "id": "nUIE9fsc9MsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\", api_url=\"https://api.hub.langchain.com\")"
      ],
      "metadata": {
        "id": "tWJT2HMo9FcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint"
      ],
      "metadata": {
        "id": "0x3JSjHm9gUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pprint(prompt)\n",
        "prompt"
      ],
      "metadata": {
        "id": "9qH1eWYa9RDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type='stuff',\n",
        "    retriever = retriever,\n",
        "    return_source_documents = True,\n",
        "    chain_type_kwargs = chain_type_kwargs,\n",
        "    verbose = True\n",
        ")\n",
        "\n",
        "# qa_chain = RetrievalQA.from_chain_type(\n",
        "#     llm,\n",
        "#     retriever=retriever,\n",
        "#     chain_type_kwargs={\"prompt\": prompt},\n",
        "#     verbose = True\n",
        "# )\n",
        "\n",
        "question = \"팀장과 팀원의 차이는?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ],
      "metadata": {
        "id": "lWuBispVyxZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이 모든 것을 한번에 해결해주는... VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "2qElk4tJu4GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "index = VectorstoreIndexCreator(\n",
        "    # 텍스트를 자르고+\n",
        "    text_splitter=splitter,\n",
        "    # 임베딩처리를 하고\n",
        "    embedding = embedding,\n",
        "    # Chroma에 로딩한다.\n",
        "    vectorstore_cls=Chroma\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "id": "tJMIuCd2u42t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.query(\n",
        "    llm = ask_openai(),\n",
        "    question = user_input,\n",
        "    chain_type = 'stuff',\n",
        "    vectorstore_kwargs = retriever\n",
        "    )"
      ],
      "metadata": {
        "id": "c1dyOrrxvLAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------"
      ],
      "metadata": {
        "id": "kOVPvYkJ1q_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 꽁수"
      ],
      "metadata": {
        "id": "ZnYj_Pjg1trZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving data to Google Drive"
      ],
      "metadata": {
        "id": "yC1FgBFw2Jqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [PyDrive reference](https://pythonhosted.org/PyDrive/)\n",
        "* [Google Drive API reference](https://developers.google.com/drive/v3/reference/)"
      ],
      "metadata": {
        "id": "nUjHDw1L2NQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': 'Sample file.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# After executing the cell above, a new file named 'Sample file.txt' will appear in your [drive.google.com](https://drive.google.com/) file list."
      ],
      "metadata": {
        "id": "ySBTF69p1yBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Listing files in Google Drive"
      ],
      "metadata": {
        "id": "A3mSNzgc2Y15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List .txt files in the root.\n",
        "#\n",
        "# Search query reference:\n",
        "# https://developers.google.com/drive/v2/web/search-parameters\n",
        "listed = drive.ListFile({'q': \"title contains '.txt' and 'root' in parents\"}).GetList()\n",
        "for file in listed:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "metadata": {
        "id": "2YG7nE_o2Z3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading files or importing data from Google Drive"
      ],
      "metadata": {
        "id": "JqrZwKL72eSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [PyDrive reference](https://pythonhosted.org/PyDrive/)\n",
        "* [Google Drive API reference](https://developers.google.com/drive/v3/reference/)"
      ],
      "metadata": {
        "id": "s0TSYRZh2mxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = 'REPLACE_WITH_YOUR_FILE_ID'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "metadata": {
        "id": "K21UWBxT2ej3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading files to your local file system"
      ],
      "metadata": {
        "id": "g1ckBSSr2srX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`files.download` will invoke a browser download of the file to your local computer."
      ],
      "metadata": {
        "id": "uBkW3dMa26uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')"
      ],
      "metadata": {
        "id": "NUMElwPu2uOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------"
      ],
      "metadata": {
        "id": "DvZbMgBD1wHK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 더 공부할 것"
      ],
      "metadata": {
        "id": "JGbMKmyNvgfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- chain 의 종류 stuff 이외에?\n",
        "chain의 옵션들. return_intermediate_steps?\n",
        "\n",
        "        load_qa_chain  \n",
        "        RetrievalQA  \n",
        "        VectorstoreIndexCreator  \n",
        "        ConversationalRetrievalChain  \n",
        "\n",
        "- chatmemory에 대한 정리\n",
        "\n",
        "- document loader option 정리\n",
        "\n",
        "- local coopilot with lm studio.\n",
        "https://www.toolify.ai/ai-news/build-your-own-coding-copilot-in-vs-code-with-colab-507366\n",
        "\n",
        "- colab with llama.cpp HF\n",
        "https://shiv248.medium.com/hosting-open-source-llm-model-on-google-colaboratory-cc14a42d4053"
      ],
      "metadata": {
        "id": "_syC2v6VvjV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랭체인에서 chain(), chain.run(), chain,invoke()의 차이."
      ],
      "metadata": {
        "id": "SuP7Qf5zwCNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- chain() 과 chain.run()은 거의 같은 기능을 했으나, 지금은 deprecate됨.\n",
        "- 현재는 chain.invoke()를 사용한다. 기능적으로는 별로 달라진거 없다."
      ],
      "metadata": {
        "id": "BKqUnh00wOHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 삽질의 추억"
      ],
      "metadata": {
        "id": "ngAAoKwsvQs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시도1 : 한번에 자료문서를 다 때려 넣으면,\n",
        "- 일단 비싸고 모델에 따라서는 처리가 불가능한 경우가 발생한다."
      ],
      "metadata": {
        "id": "66ur5HREvWQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# chain = load_qa_chain(llm = ask_openai(), chain_type='stuff', verbose=True)\n",
        "# user_input = '아내가 먹고 싶은 것은?'\n",
        "# chain.run(input_documents=docs, question=user_input)\n",
        "\n",
        "'''\n",
        "BadRequestError: Error code: 400 - {\n",
        "    'error': {\n",
        "      'message': \"This model's maximum context length is 4097 tokens,\n",
        "      however you requested 11185 tokens (10929 in your prompt; 256 for the completion).\n",
        "      Please reduce your prompt; or completion length.\",\n",
        "      'type': 'invalid_request_error',\n",
        "      'param': None, 'code': None\n",
        "      }\n",
        "      }\n",
        "'''"
      ],
      "metadata": {
        "id": "Y7CaYy1RvPq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}