{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN48YdyREtlXEh5QwewEqXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genie0320/langchain/blob/main/04_RAG_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lAI_KciVRoq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9355a0da-3049-42a8-9023-8751937a0872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# colab 환경설정\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "os.environ['HF_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U -q langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ej2EeSEu7e",
        "outputId": "235539f9-62fb-494e-e6eb-460c27342a6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm=ChatGoogleGenerativeAI(model='gemini-pro')\n",
        "result = llm.invoke('현금 달러투자에 대해서 설명해줘')\n",
        "Markdown(result.content)"
      ],
      "metadata": {
        "id": "wkpzi-UZEla4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain tiktoken pypdf sentence_transformers chromadb"
      ],
      "metadata": {
        "id": "TUEmz74FFKxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "\n",
        "SOURCE_folder = \"/content/drive/MyDrive/data/brand\"\n",
        "\n",
        "loader = DirectoryLoader(SOURCE_folder, glob='**/*.pdf', show_progress=True, loader_cls=PyPDFLoader)\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)\n",
        "texts = text_splitter.split_documents(pages)\n",
        "\n",
        "# for p in pages[0:10]:\n",
        "#     with open('/content/drive/MyDrive/foo.txt', 'a') as f:\n",
        "#         f.write(p.page_content)\n",
        "\n",
        "!head -n 10 '/content/drive/MyDrive/foo.txt'"
      ],
      "metadata": {
        "id": "q53hU0DkHbRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DB_URL = '/content/drive/MyDrive/vector_chrm_gemini/'\n",
        "# texts = tk_chunks"
      ],
      "metadata": {
        "id": "emI7AbSDJ07O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "query = '네이밍의 본질이 무엇인가'\n",
        "\n",
        "# ko_embed = HuggingFaceEmbeddings(\n",
        "#     model_name=\"jhgan/ko-sbert-nli\",\n",
        "#     model_kwargs={'device' : 'cpu'},\n",
        "#     encode_kwargs={'normalize_embeddings':True}\n",
        "#     )\n",
        "# # vector_stores = Chroma.from_documents(texts, hug_embed)\n",
        "# vector_stores = Chroma.from_documents(\n",
        "#     texts,\n",
        "#     ko_embed,\n",
        "#     persist_directory = DB_URL\n",
        "# )\n",
        "# print('hug_embed : Document Stored!!')\n",
        "\n",
        "load_vector_store = Chroma(\n",
        "    persist_directory = DB_URL,\n",
        "    embedding_function = ko_embed,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVT0SRw-KH_0",
        "outputId": "e30b3e50-4c9f-4be3-8e85-922ae17604d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hug_embed : Document Stored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = load_vector_store.as_retriever(\n",
        "    search_type='mmr',\n",
        "    search_kwargs = {'k':3, 'fetch_k':10}\n",
        ")\n",
        "\n",
        "retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "HRkhJ4rjKrAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "\n",
        "template='''Answer the question as based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "'''\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "_AP5xDo7LsRt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_chat = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0)\n",
        "\n",
        "chain = RunnableMap({\n",
        "    \"context\" : lambda x : retriever.get_relevant_documents(x['question']),\n",
        "    'question' : lambda x: x['question']\n",
        "}) | prompt | gemini_chat\n",
        "\n",
        "Markdown(chain.invoke({'question' : query }).content)"
      ],
      "metadata": {
        "id": "Ze7PtOohMOSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}