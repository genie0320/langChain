{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5wYw4i7hyCfYUdhhpk2av",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genie0320/langchain/blob/main/04_RAG_Ensemble_retriever.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriever"
      ],
      "metadata": {
        "id": "SqPa9SjtqcwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sparse / Dense"
      ],
      "metadata": {
        "id": "aAsOW9T8j2yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앙상블 : 2가지 방식을 써서... 더 정확한 답을 얻을 수 있도록 한다.\n",
        "롱컨텍스트 : AI가 똑똑하군..."
      ],
      "metadata": {
        "id": "-6sACMfdm1ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # colab 환경설정\n",
        "# import os\n",
        "# from google.colab import userdata\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "# os.environ['HF_TOKEN'] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "# from google.colab import drive as gd\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nj2MsACEort7"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --quiet icecream > /dev/null"
      ],
      "metadata": {
        "id": "wy22SDYmqK7y"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pprint\n",
        "# from icecream import ic\n",
        "\n",
        "# def pp(object):\n",
        "#   ppr = pprint.PrettyPrinter(\n",
        "#       # indent=40,\n",
        "#       width=80\n",
        "#       )\n",
        "#   return ppr.pprint(object)"
      ],
      "metadata": {
        "id": "Z_gxlLIkqIbp"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensenble"
      ],
      "metadata": {
        "id": "q4Y-36pJqWgR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "C-BXEShkjXMe"
      },
      "outputs": [],
      "source": [
        "# pip install -q langchain langchain-openai pypdf sentence-transformers chromadb  faiss-cpu -U rank_bm25 > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "kp6kJfbzmz1d"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ko_embed = HuggingFaceEmbeddings(\n",
        "    model_name=\"jhgan/ko-sbert-nli\",\n",
        "    model_kwargs={'device' : 'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings':True}\n",
        "    )"
      ],
      "metadata": {
        "id": "0SJ0KR8QoTY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
        "\n",
        "SOURCE_folder = \"/content/drive/MyDrive/data/brand\"\n",
        "SOURCE = \"/content/source/1-1그로스 해킹, 마케팅과 어떻게 다른가요_ - PUBLY.pdf\"\n",
        "\n",
        "loader = DirectoryLoader(\n",
        "    SOURCE_folder,\n",
        "    glob='**/*.pdf',\n",
        "    show_progress=True,\n",
        "    loader_cls=PyPDFLoader,\n",
        "    )\n",
        "\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "# 이건 여러번의 로더 호출을 통해, 각 문서가 각각의 로더객체에 담겼을 경우,\n",
        "# 이 모두를 합해서 하나의 doc 객체로 만들어서 downstream에서 이용하기 위해 합쳐주는 기능.\n",
        "# 따라서... 우리는 디렉토리 로더로 어차피 하나의 객체에 모든 문서를 '페이지별'로 담았다.\n",
        "# 이 pypdf는 내부적으로 리컬시브~를 쓴다고 한다.\n",
        "# docs = []\n",
        "# for page in pages:\n",
        "#     docs.append(page.page_content)\n",
        "\n",
        "ic(len(pages))"
      ],
      "metadata": {
        "id": "jkKTlw4uocKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad5c2ed-5453-4b65-af38-c8ab013022af"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
            "100%|██████████| 3/3 [00:03<00:00,  1.00s/it]\n",
            "ic| len(pages): 47, len(pages_02): 47\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47, 47)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이걸 문서별로 덩어리로 만들고 싶다. 즉 불러온 문서가 3개라면, 객체속의 요소도 3개만 존재하도록.\n",
        "# keys = []\n",
        "# for page in pages:\n",
        "#     source = page.metadata['source']\n",
        "#     if source not in keys:\n",
        "#         keys.append(page.metadata['source'])\n",
        "# keys\n",
        "\n",
        "# 그러나 지금은 일단 포기\n",
        "\n",
        "lens = []\n",
        "for page in pages:\n",
        "    lens.append(len(page.page_content))\n",
        "\n",
        "print(sorted(lens, reverse = True), end=' ')\n",
        "print('\\n','*'*100, '\\n')\n",
        "print(min(lens), max(lens))\n",
        "\n",
        "docs = pages"
      ],
      "metadata": {
        "id": "K26pGycn3rAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35417f98-8e0a-4574-ea6e-0009a0e2f1fc"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1498, 1409, 1283, 1240, 1236, 1225, 1217, 1202, 1187, 1175, 1161, 1134, 1120, 1105, 1085, 1079, 977, 945, 909, 904, 857, 812, 801, 795, 794, 781, 776, 769, 757, 752, 734, 729, 727, 708, 701, 676, 675, 635, 626, 592, 585, 472, 446, 446, 407, 320, 281] \n",
            " **************************************************************************************************** \n",
            "\n",
            "281 1498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 적정한 길이로 잘라주고\n",
        "rc_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=350,\n",
        "    chunk_overlap=30,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "# chunks = rc_splitter.create_documents(docs) # 옵션을 줄 수 있다. []을 받는다.\n",
        "chunks = rc_splitter.split_documents(docs) # 옵션을 줄 수 있다. []을 받는다.\n",
        "\n",
        "len(chunks)\n",
        "\n",
        "lens = []\n",
        "for chunk in chunks:\n",
        "    lens.append(len(chunk.page_content))\n",
        "\n",
        "print(sorted(lens, reverse = True), end=' ')\n",
        "print('\\n','*'*100, '\\n')\n",
        "print(min(lens), max(lens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNleX-L0pH9k",
        "outputId": "fdf471cc-3421-4944-df45-2d34cdf20fca"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[350, 349, 349, 348, 347, 347, 346, 346, 346, 345, 344, 343, 343, 343, 343, 343, 342, 341, 340, 340, 340, 339, 339, 339, 338, 338, 338, 337, 337, 336, 335, 335, 335, 334, 334, 334, 334, 334, 334, 334, 334, 334, 334, 333, 333, 332, 332, 331, 331, 330, 330, 330, 329, 329, 328, 328, 327, 327, 327, 326, 325, 324, 324, 323, 322, 322, 320, 319, 319, 319, 319, 319, 318, 318, 318, 317, 317, 317, 315, 315, 314, 314, 314, 314, 313, 313, 312, 312, 311, 311, 310, 309, 309, 308, 307, 306, 305, 305, 304, 302, 300, 300, 300, 295, 294, 290, 281, 279, 258, 255, 250, 245, 243, 238, 233, 224, 221, 214, 202, 201, 197, 194, 191, 185, 147, 146, 145, 145, 143, 142, 142, 139, 129, 128, 125, 114, 109, 106, 99, 87, 84, 83, 78, 70, 69] \n",
            " **************************************************************************************************** \n",
            "\n",
            "69 350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_ret = BM25Retriever.from_documents(chunks)\n"
      ],
      "metadata": {
        "id": "BvZXN1KqJf65"
      },
      "execution_count": 106,
      "outputs": []
    }
  ]
}