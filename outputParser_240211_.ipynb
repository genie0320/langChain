{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9XZJdcyO7y-B",
        "W7uajFbV74Fc",
        "saZpjYvUBBFb",
        "YyEwKsUIK4m3",
        "uQya__vwLjPx",
        "mWhgK78Vg1mq",
        "vF7binRsg_RM",
        "Maxtrjvf76nw",
        "9CCFYpDw8LT2",
        "pcPfoQZ4HrCd",
        "VXuDjKwLH6o1",
        "CGg0TCX6Fo9s"
      ],
      "authorship_tag": "ABX9TyM6mK4nkOPkFMT4Q9/QRNJZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genie0320/langchain/blob/main/outputParser_240211_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set environment"
      ],
      "metadata": {
        "id": "9XZJdcyO7y-B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vZx3RoVgGX2Z"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dNxXQ33wIL9j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# colab 환경설정\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "HUGGINGFACEHUB_API_TOKEN = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ],
      "metadata": {
        "id": "W_3FW-LSH728"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q icecream"
      ],
      "metadata": {
        "id": "wSWuG1_s_9rM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from icecream import ic\n",
        "import pprint"
      ],
      "metadata": {
        "id": "IIuXaZ6nLl_O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set LLMs"
      ],
      "metadata": {
        "id": "W7uajFbV74Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q -U langchain-openai"
      ],
      "metadata": {
        "id": "HghRxstg6g2u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "compbot = OpenAI()"
      ],
      "metadata": {
        "id": "LPRMv9y_5-tv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "MODEL = 'gpt-3.5-turbo'\n",
        "chatbot = ChatOpenAI(\n",
        "    model_name = MODEL,\n",
        "    temperature=0.7,\n",
        "    max_tokens = 300\n",
        ")"
      ],
      "metadata": {
        "id": "Y5zwjIV37Nwz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt"
      ],
      "metadata": {
        "id": "saZpjYvUBBFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "프롬프트에는 최소 2종류가 있는데,\n",
        "- `PromptTemplate` : 일방적인 대답을 요구하는  \n",
        "- `ChatPromptTemplate : `대화를 요구하는(그래서 나중에 히스토리로 쌓거나 할 때도 도움이 되는)\n",
        "\n",
        "`from_template`로 틀을 잡고, `formate_prompt`로 값을 넣어주면 완성됨.\n",
        "그리고 format된 결과물을 llm에 넘겨주면 대답을 해준다."
      ],
      "metadata": {
        "id": "PQxr15V8COJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Completion"
      ],
      "metadata": {
        "id": "aZOehV72LZMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
        "\n",
        "# prompt_template = PromptTemplate.from_template('{subject}에 대한 재미있는 한문장짜리 농담을 해볼래?')\n",
        "# prompt = prompt_template.format_prompt(subject='패션')\n",
        "\n",
        "# res_comp = compbot.invoke(prompt)"
      ],
      "metadata": {
        "id": "omK4kMfNBAmb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ic(prompt_template) # PromptTemplate(input_variables=['subject'], template='{subject}에 대한 재미있는 한문장짜리 농담을 해볼래?')\n",
        "# ic(prompt) # StringPromptValue(text='패션에 대한 재미있는 한문장짜리 농담을 해볼래?')\n",
        "# prompt.to_string() # 패션에 대한 재미있는 한문장짜리 농담을 해볼래?\n",
        "# ic(res_comp)"
      ],
      "metadata": {
        "id": "4IQ55K3VFgFe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 아래처럼 구성할 수도 있다. 사실 이쪽을 더 많이 쓴다.\n",
        "template를 구성하면서 다양한 variable을 줄 수 있고, 이 변수값들은 여러가지 단계를 거치면서 채워질 수 있기 때문이다.(이를테면 문서검색결과, 웹검색결과, 사용자입력 등... )"
      ],
      "metadata": {
        "id": "YyEwKsUIK4m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# template = '''\n",
        "# 다음 주제에 대한 재미있는 한문장짜리 농담을 해볼래?\n",
        "\n",
        "# <주제>\n",
        "# {subject}\n",
        "# '''\n",
        "\n",
        "# prompt_template_02 = PromptTemplate(\n",
        "#     input_variables=['subject'],\n",
        "#     template = template\n",
        "# )\n",
        "\n",
        "# prompt_02 = prompt_template_02.format(subject = '패션')\n",
        "\n",
        "# res_comp_02 = compbot.invoke(prompt_02)"
      ],
      "metadata": {
        "id": "4aFibwGoJIrN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ic(prompt_template_02)\n",
        "# ic(prompt_02) # HumanMessage가 생성되는 것에 유의.\n",
        "# prompt_02\n",
        "# ic(res_comp_02) # AIMessage로 돌아오는 것에 유의."
      ],
      "metadata": {
        "id": "RN3FhKYuKhws"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat_prompt_template = ChatPromptTemplate.from_template('{subject}에 대한 재미있는 한문장짜리 농담을 해볼래?')\n",
        "# # chat_prompt = chat_prompt_template.format_messages(subject = '군고구마')\n",
        "# chat_prompt = chat_prompt_template.format_prompt(subject = '군고구마')\n",
        "\n",
        "# res_chat = chatbot.invoke(chat_prompt)"
      ],
      "metadata": {
        "id": "yy-9BHqOCElv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ic(chat_prompt_template)\n",
        "# ic(chat_prompt) # HumanMessage가 생성되는 것에 유의.\n",
        "# chat_prompt.to_string\n",
        "# ic(res_chat) # AIMessage로 돌아오는 것에 유의."
      ],
      "metadata": {
        "id": "FK2bF5WNFiRc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat"
      ],
      "metadata": {
        "id": "uQya__vwLjPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용방법  \n",
        "1. 전달할 template를 만들고  \n",
        "`SystemMessagePromptTemplate.from_template(system_setting)`  \n",
        "2. 그걸 prompt로 만들고    \n",
        "`ChatPromptTemplate.from_messages([instruction, question])`  \n",
        "3. 그 prompt에 query를 넣어서  \n",
        "`chat_prompt = chat_prompt_template_02.format_prompt(subject = '군고구마').to_messages()`  \n",
        "4. 발사.  \n",
        "`invoke()`\n",
        "\n",
        "잘못된 예 :  \n",
        "- 최종 prompt는 format_prompt로 다듬어줘야 함.  \n",
        "`chat_prompt = chat_prompt_template_02.format(subject = '군고구마')`  "
      ],
      "metadata": {
        "id": "j6sJ6xihUceV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate\n",
        ")\n",
        "\n",
        "# from langchain.schema import (\n",
        "#     SystemMessage,\n",
        "#     HumanMessage,\n",
        "#     AIMessage\n",
        "# )"
      ],
      "metadata": {
        "id": "LoGCqHRTLmHn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_setting = '다음 주제에 대한 재미있는 한문장짜리 농담을 해볼래?'\n",
        "instruction = SystemMessagePromptTemplate.from_template(system_setting)\n",
        "\n",
        "# user_input = input('주제를 알려주세요.')\n",
        "user_input = '{subject}'\n",
        "question = HumanMessagePromptTemplate.from_template(user_input) # 사용자 입력부는, 가장 나중에 전달될 것이므로 '변수' 그 자체로 전달.\n",
        "\n",
        "chat_prompt_template_02 = ChatPromptTemplate.from_messages([instruction, question]) # 위에서 각 만든 부품들을 조립해서 하나의 template로 만들고,..단 1개밖에 전달이 안되므로 배열로 감싸서 던진다.\n",
        "\n",
        "chat_prompt_02 = chat_prompt_template_02.format_prompt(subject = '군고구마').to_messages() # 거기다가 마지막 사용자 질문을 입력해서 프롬프트를 완성.\n",
        "\n",
        "# res_chat_03 = chatbot.invoke(chat_prompt_02)"
      ],
      "metadata": {
        "id": "_lJDdw69MNL9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ic(instruction)\n",
        "# ic(question)\n",
        "# ic(chat_prompt_template_02)\n",
        "# ic(chat_prompt_02)\n",
        "# ic(res_chat_03)\n",
        "# print('\\n\\n', res_chat_03.content )"
      ],
      "metadata": {
        "id": "gfefsitvPUD0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "system_msg = SystemMessagePromptTemplate.from_template('사용자가 전달하는 숫자에 다음의 숫자를 더해줘.')\n",
        "repeat = str(random.randrange(0,50))\n",
        "user_input = '16'\n",
        "human_msg = HumanMessagePromptTemplate.from_template(user_input)\n",
        "prompt_full = ChatPromptTemplate.from_messages([system_msg, repeat, human_msg])\n",
        "\n",
        "# res_full = chatbot.invoke(prompt_full.format_prompt())\n",
        "# res_full"
      ],
      "metadata": {
        "id": "mAbI5P1qYIYL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering"
      ],
      "metadata": {
        "id": "Mm4IZzpedkG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-shot"
      ],
      "metadata": {
        "id": "mWhgK78Vg1mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "백문이 불여일견이라는 말은 AI에게도 통하는 모양이다. 내가 원하는 결과물의 형태가 있는 경우, 구질구질 설명하지 말고 깔끔하게 샘플을 만들어서 보내주면 그걸 응용해서 결과물을 뽑아준다."
      ],
      "metadata": {
        "id": "OOi7l39-dr_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "      \"question\": \"초등학교때는 어땠어?\",\n",
        "      \"answer\": \"\"\"\n",
        "        초등학교때 선생님은 너무 좋았어.\n",
        "        하지만 애들이 나를 싫어했었어.\n",
        "        그래서 별로 재미가 없었어.\n",
        "        \"\"\",\n",
        "    },\n",
        "    {\n",
        "      \"question\": \"중학교때는 어땠어?\",\n",
        "      \"answer\": \"\"\"\n",
        "        중학교때 선생님은 좀 싫었어.\n",
        "        하지만 애들이 나를 많이 좋아했었어.\n",
        "        그래서 연애도 많이 했지.\n",
        "        \"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"고등학교때는 어땠어?\",\n",
        "        \"answer\": \"\"\"\n",
        "        고등학교때 선생님은 예뻤어.\n",
        "        애들도 많이 좋아했었어.\n",
        "        그래서 나도 공부를 열심히 했지.\n",
        "        \"\"\",\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "VLJ6zQVmh0Io"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\", \"answer\"],\n",
        "    template=\"Question: {question}\\nAnswer:{answer}\"\n",
        ")\n",
        "\n",
        "# print(prompt_template.format(**examples[0]))"
      ],
      "metadata": {
        "id": "wVK_ZCz-h0Ey"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotPromptTemplate( # 여기에서 비로소 FewShot~이 등장한다.\n",
        "    examples=examples,\n",
        "    example_prompt=prompt_template,\n",
        "    suffix=\"Question: {input}\", # suffix의 의미는... 'input값은 **이따가** 줄건데, 그건 Question 옆에다가 배치해줘...'\n",
        "    input_variables=[\"input\"],\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.format(input=\"대학교때는 어땠어?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExF0Z_9ah0CB",
        "outputId": "7c65a91a-6337-425b-8c93-74068a14d22a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 초등학교때는 어땠어?\n",
            "Answer:\n",
            "        초등학교때 선생님은 너무 좋았어. \n",
            "        하지만 애들이 나를 싫어했었어. \n",
            "        그래서 별로 재미가 없었어.\n",
            "        \n",
            "\n",
            "Question: 중학교때는 어땠어?\n",
            "Answer:\n",
            "        중학교때 선생님은 좀 싫었어.\n",
            "        하지만 애들이 나를 많이 좋아했었어.\n",
            "        그래서 연애도 많이 했지.\n",
            "        \n",
            "\n",
            "Question: 고등학교때는 어땠어?\n",
            "Answer:\n",
            "        고등학교때 선생님은 예뻤어.\n",
            "        애들도 많이 좋아했었어. \n",
            "        그래서 나도 공부를 열심히 했지.\n",
            "        \n",
            "\n",
            "Question: 대학교때는 어땠어?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chatbot.invoke(few_shot_prompt.format(input=\"대학교때는 어땠어?\"))"
      ],
      "metadata": {
        "id": "K8y85Vonhz2S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example selector"
      ],
      "metadata": {
        "id": "vF7binRsg_RM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "세상에 질문은 많고, 인간의 감정을 '배워야만 알 수 있는' AI한계는 분명하다. 다양한 유형의 요구에, 붙어 앉아서 적절한 example set을 먹여줘야 원하는 결과를 얻을 수 있다는 건 어불성설이니, 몇가지 예시덩어리를 던져주고, 사용자의 요구에 따라 적절한 예시덩어리를 '선택'하여 활용할 수 있도록 해야 한다.  \n",
        "\n",
        "단, 이 '선택하는 행위'를 LLM이 직접 하게되면, 그 많은 예시덩어리를 다 일단 넘겨서(자원낭비, 리스크컨트롤) 죄다 한번씩 훑어보게 해야 할 것이다. 그래서 중간관리자가 살펴보고 적절한 예시덩어리를 골라서 최종처리자 LLM에게 던져줄 필요가 발생한다.\n",
        "\n",
        "- 이게 느낌상... router같은데...\n",
        "- agent tool 이랑 langgraph 같기도 하고?"
      ],
      "metadata": {
        "id": "8fd4BtwrhClE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q chromadb tiktoken"
      ],
      "metadata": {
        "id": "Nid70qlTt5ja"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Completion"
      ],
      "metadata": {
        "id": "X03KdlJvAdm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. 내가 원하는 건 이거야."
      ],
      "metadata": {
        "id": "OLQdhV5_77bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종적으로 내가 원하는 답변 템플릿 구성.\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables = ['input', 'output'],\n",
        "    template='input: {input}\\nOutput:{output}'\n",
        ")"
      ],
      "metadata": {
        "id": "iBul3Fqd7bIu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. 네가 사용할 수 있는 자료들"
      ],
      "metadata": {
        "id": "Maxtrjvf76nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
        "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
        "    {\"input\": \"2+4\", \"output\": \"6\"},\n",
        "    {\"input\": \"정치인들에 대해서 어떻게 생각해?\", \"output\": \"정치이야기는 싫어\"},\n",
        "    {\"input\": \"사내정치에 대해서 어떻게 생각해?\", \"output\": \"정치이야기는 싫어\"},\n",
        "    {\"input\": \"종교인들에 대해서 어떻게 생각해?\", \"output\": \"종교이야기는 싫어\"},\n",
        "    {\"input\": \"결혼생활에 대해서 어떻게 생각해?\", \"output\": \"결혼은 하면 미친짓, 안하면 바보짓이야\"},\n",
        "    {\"input\": \"대학생활에 대해서 어떻게 생각해?\", \"output\": \"대학은 가면 자원낭비 안가면 인생낭비야\"},\n",
        "    {\n",
        "        \"input\": \"나비에 대한 노래를 불러줘\",\n",
        "        \"output\": \"나비야 나비야 이리날아 오너라.\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"학교 종에 대한 노래를 불러줘\",\n",
        "        \"output\": \"학교종이 떙떙땡 어서 모이자\",\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "FRPMoPlTT1L_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. 너를 도와주실 매니저님을 소개할께."
      ],
      "metadata": {
        "id": "TkQNa0Qs8Rka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import SemanticSimilarityExampleSelector\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "aW7C9mZnICBq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
      ],
      "metadata": {
        "id": "YaUG8deKuLk6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_manager = SemanticSimilarityExampleSelector(\n",
        "    vectorstore=vectorstore,\n",
        "    k=2,\n",
        ")\n",
        "\n",
        "# The prompt template will load examples by passing the input do the `select_examples` method\n",
        "# my_manager.select_examples({\"input\": \"병아리\"})\n",
        "\n",
        "'''\n",
        "# 이렇게 통으로 해버리는 것도 가능은 하지만 좋은 예는 아닌듯?\n",
        "# 계속 embedding을 반복할 테니.\n",
        " my_manager_total = SemanticSimilarityExampleSelector.from_examples(\n",
        "     examples,\n",
        "     OpenAIEmbeddings(),\n",
        "     Chroma,\n",
        "     k=1\n",
        " )\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "hzdpeJ35uL2w",
        "outputId": "178dbd39-ed67-462b-d5b5-98eced89f6a8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 이렇게 통으로 해버리는 것도 가능은 하지만 좋은 예는 아닌듯?    \\n# 계속 embedding을 반복할 테니.  \\n my_manager_total = SemanticSimilarityExampleSelector.from_examples(\\n     examples,\\n     OpenAIEmbeddings(),\\n     Chroma,\\n     k=1\\n )\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. 그러니까 말이지..."
      ],
      "metadata": {
        "id": "9CCFYpDw8LT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 매니저가 없는 경우"
      ],
      "metadata": {
        "id": "pcPfoQZ4HrCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=[\"input\"],\n",
        ")\n",
        "\n",
        "print(prompt.format(input=\"병아리\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDk-Rf0THuC2",
        "outputId": "ca2c8a3d-c9e9-4838-ff51-a278a9965ec0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: 2+2\n",
            "Output:4\n",
            "\n",
            "input: 2+3\n",
            "Output:5\n",
            "\n",
            "input: 2+4\n",
            "Output:6\n",
            "\n",
            "input: 정치인들에 대해서 어떻게 생각해?\n",
            "Output:정치이야기는 싫어\n",
            "\n",
            "input: 사내정치에 대해서 어떻게 생각해?\n",
            "Output:정치이야기는 싫어\n",
            "\n",
            "input: 종교인들에 대해서 어떻게 생각해?\n",
            "Output:종교이야기는 싫어\n",
            "\n",
            "input: 결혼생활에 대해서 어떻게 생각해?\n",
            "Output:결혼은 하면 미친짓, 안하면 바보짓이야\n",
            "\n",
            "input: 대학생활에 대해서 어떻게 생각해?\n",
            "Output:대학은 가면 자원낭비 안가면 인생낭비야\n",
            "\n",
            "input: 나비에 대한 노래를 불러줘\n",
            "Output:나비야 나비야 이리날아 오너라.\n",
            "\n",
            "input: 학교 종에 대한 노래를 불러줘\n",
            "Output:학교종이 떙떙땡 어서 모이자\n",
            "\n",
            "Question: 병아리\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 매니저가 있는 경우"
      ],
      "metadata": {
        "id": "VXuDjKwLH6o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"병아리\"\n",
        "selected_examples = my_manager.select_examples({\"question\": question})\n",
        "# print(f\"Examples most similar to the input: {question}\")\n",
        "# for example in selected_examples:\n",
        "#     print(\"\\n\")\n",
        "#     for k, v in example.items():\n",
        "#         print(f\"{k}: {v}\")\n",
        "\n",
        "\n",
        "prompt_comp = FewShotPromptTemplate(\n",
        "    example_selector = my_manager, # 매니저님이 골라주시는 샘플을 참고해서\n",
        "    example_prompt = example_prompt, # 내가 처음에 물었던 대로 대답해주면 되.\n",
        "    prefix='사용자의 질문유형에 맞는 대답을 해줘~', # 이건 optional.\n",
        "    suffix='input:{input}', # 내 질문이 뭔지는 이따가 알려줄텐데\n",
        "    input_variables =['input'] # input 이라는 자리에 넣어서 잘 생각해봐.\n",
        ")"
      ],
      "metadata": {
        "id": "my5VnIsK48T8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ic(prompt_comp.format(input='병아리'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b9zdDkl585Xz",
        "outputId": "d640fe34-8e60-41fd-f2f2-2ebe41f8de88"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| prompt_comp.format(input='병아리'): ('사용자의 질문유형에 맞는 대답을 해줘~\n",
            "                                     '\n",
            "                                      '\n",
            "                                     '\n",
            "                                      'input: 나비에 대한 노래를 불러줘\n",
            "                                     '\n",
            "                                      'Output:나비야 나비야 이리날아 오너라.\n",
            "                                     '\n",
            "                                      '\n",
            "                                     '\n",
            "                                      'input: 학교 종에 대한 노래를 불러줘\n",
            "                                     '\n",
            "                                      'Output:학교종이 떙떙땡 어서 모이자\n",
            "                                     '\n",
            "                                      '\n",
            "                                     '\n",
            "                                      'input:병아리')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사용자의 질문유형에 맞는 대답을 해줘~\\n\\ninput: 나비에 대한 노래를 불러줘\\nOutput:나비야 나비야 이리날아 오너라.\\n\\ninput: 학교 종에 대한 노래를 불러줘\\nOutput:학교종이 떙떙땡 어서 모이자\\n\\ninput:병아리'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compbot.invoke(prompt_comp.format(input='병아리'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MhKeWbzE_zF9",
        "outputId": "030c5eab-482a-41a4-8120-84eb42c547bc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'에 대한 노래를 불러줘\\nOutput:병아리병아리 꼬끼오 이리와 저리와 병아리야'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat (아마도 여기서 RAG로 바로 이어지겠지)"
      ],
      "metadata": {
        "id": "zZSkNDdmASpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    FewShotChatMessagePromptTemplate,\n",
        ")"
      ],
      "metadata": {
        "id": "fXKFxyJvus19"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### completion과 동일한 부분."
      ],
      "metadata": {
        "id": "uI5YTu2IA9LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 내가 원하는건 이거야\n",
        "example_chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 네가 사용할 수 있는 자료는 이거야\n",
        "# examples\n",
        "# 너를 도와주실 매니저님을 소개할께.\n",
        "# my_manager"
      ],
      "metadata": {
        "id": "2dBdqDVL2R9K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the few-shot prompt.\n",
        "```python\n",
        "selected_example = FewShotChatMessagePromptTemplate(\n",
        "    # The input variables select the values to pass to the example_selector\n",
        "    input_variables=[\"input\"],\n",
        "    example_selector=my_manager,\n",
        "    # Define how each example will be formatted.\n",
        "    # In this case, each example will become 2 messages:\n",
        "    # 1 human, and 1 AI\n",
        "    example_prompt=ChatPromptTemplate.from_messages(\n",
        "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
        "    ), # example_prompt를 따로 정의하지 않고 바로 여기서 넘기는 것도 가능.\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "T49iAXFnCci-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 매니저가 없는 경우"
      ],
      "metadata": {
        "id": "M2Jp2TevKKMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래서 결론적으로 다시 정리하자면...\n",
        "few_shot_chat = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt = example_chat_prompt, # 내가 처음에 물었던 대로 대답해주면 되.\n",
        "    examples = examples, # 자료를 참고해서\n",
        "    # prefix='', # 이건 optional.\n",
        "    # suffix='Input:{input}\\nOutput:', # 내 질문이 뭔지는 이따가 알려줄텐데\n",
        "    input_variables =['input'] # input 이라는 자리에 넣어서 잘 생각해봐.\n",
        ")"
      ],
      "metadata": {
        "id": "8pVVb84NKSl0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"사용자의 질문유형에 맞는 대답을 해줘~\"),\n",
        "        few_shot_chat,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "1pPZ8CvfK7d5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.invoke(final_prompt.format(input='병아리'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjahAzOSKeU7",
        "outputId": "b8f9ad94-42e8-4266-a4b2-a892dde4cd5f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='AI: 병아리 병아리 삐약 삐약')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 매니저가 있는 경우"
      ],
      "metadata": {
        "id": "jJ7zTwhQNLTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import SemanticSimilarityExampleSelector\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "SSxgkHjdNWid"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래서 결론적으로 다시 정리하자면...\n",
        "few_shot_chat_manager = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt = example_chat_prompt,\n",
        "    example_selector=my_manager,\n",
        "    # prefix='사용자의 질문유형에 맞는 대답을 해줘~', # 이건 optional. > 사용불가.\n",
        "    # suffix='Input:{input}\\nOutput:', # 내 질문이 뭔지는 이따가 알려줄텐데 > 사용불가\n",
        "    input_variables =['input'] # input 이라는 자리에 넣어서 잘 생각해봐.\n",
        "    # example_prompt=ChatPromptTemplate.from_messages(\n",
        "    #     [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
        "    # ),\n",
        ")"
      ],
      "metadata": {
        "id": "1Jh81RPRNj7V"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_manager.select_examples({\"input\": \"병아리\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av5WG6udOzNj",
        "outputId": "cbdc0aa9-64f6-46f0-8b0b-dcc93c0a8a2c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': '나비에 대한 노래를 불러줘', 'output': '나비야 나비야 이리날아 오너라.'},\n",
              " {'input': '학교 종에 대한 노래를 불러줘', 'output': '학교종이 떙떙땡 어서 모이자'}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"사용자의 질문유형에 맞는 대답을 해줘~\"),\n",
        "        few_shot_chat_manager,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "xwqkWsB12RuL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.invoke(final_prompt.format(input='병아리'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbKL8EmOOpzT",
        "outputId": "e8f27da5-7a54-4db2-cde0-3b3787834f96"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='AI: 병아리 병아리 꼬끼오, 작은 날개 펄럭이며 행복하게 살아요~')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Parser"
      ],
      "metadata": {
        "id": "gYeQJJOZTv_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정하게 원하는 출력형태가 있는 경우, 파서를 사용해서 고정해줄 수 있다. 만약에... API등을 구성한다면, 고정된 형태로 반환값이 와야 하기때문에... 또는 다음 과정에서 보다 편안하게 받아쓸 수 있도록 하기 위한 용도로 사용된다.   \n",
        "무엇보다... 파서를 쓰는게 베스트 프랙티스라고 하니 꼭 쓰자."
      ],
      "metadata": {
        "id": "PuqrPzRET5pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts import PromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_openai import OpenAI, ChatOpenAI"
      ],
      "metadata": {
        "id": "ulZ93C4UTuvG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = CommaSeparatedListOutputParser()"
      ],
      "metadata": {
        "id": "lQyPBUIKWCId"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "format_instructions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cIoPMDuAWKYF",
        "outputId": "d9ce73a3-278e-491b-eae7-ce365e24c313"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")"
      ],
      "metadata": {
        "id": "m8GE8BspXfRv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = compbot.invoke('패션영화 5개를 추천해줘')"
      ],
      "metadata": {
        "id": "AeqzGboWXf2O"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약에 프롬프트에 변수를 심어주고 싶다면... 아마도 `prompt.format({variable})`으로 다듬어 줘야겠징."
      ],
      "metadata": {
        "id": "-gmcD6lWZhoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Q3Fo7Sa4XgA-",
        "outputId": "0106ad19-f641-4f64-9176-9a5b7c04537a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1. \"Devil Wears Prada\" (2006): 뉴욕 패션 매거진 편집장의 조연으로 일하게 된 젊은 여성의 성장과 패션 산업의 내부를 다루는 작품.\\n\\n2. \"Coco Before Chanel\" (2009): 유명한 디자이너 코코 샤넬의 전성기 이전의 삶과 패션에 대한 열정적인 여성의 이야기.\\n\\n3. \"The September Issue\" (2009): 패션 매거진 Vogue의 2007년 9월호를 준비하는 과정과 편집장 애나 윈투어의 열정과 집착을 담은 다큐멘터리.\\n\\n4. \"Yves Saint Laurent\" (2014): 가장 영향력 있는 디자이너 중 하나인 이브 생 로랑의 성장과 업적'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser.parse(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1VTlIQ0ckF9",
        "outputId": "b2876744-5d5e-44f4-dd63-bab2642fe981"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. \"Devil Wears Prada\" (2006): 뉴욕 패션 매거진 편집장의 조연으로 일하게 된 젊은 여성의 성장과 패션 산업의 내부를 다루는 작품.\\n\\n2. \"Coco Before Chanel\" (2009): 유명한 디자이너 코코 샤넬의 전성기 이전의 삶과 패션에 대한 열정적인 여성의 이야기.\\n\\n3. \"The September Issue\" (2009): 패션 매거진 Vogue의 2007년 9월호를 준비하는 과정과 편집장 애나 윈투어의 열정과 집착을 담은 다큐멘터리.\\n\\n4. \"Yves Saint Laurent\" (2014): 가장 영향력 있는 디자이너 중 하나인 이브 생 로랑의 성장과 업적']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser.invoke(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRFHGt8Ub_Rh",
        "outputId": "fa90ef4e-382b-4b4d-d1cc-f27281ad6cb3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. \"Devil Wears Prada\" (2006): 뉴욕 패션 매거진 편집장의 조연으로 일하게 된 젊은 여성의 성장과 패션 산업의 내부를 다루는 작품.\\n\\n2. \"Coco Before Chanel\" (2009): 유명한 디자이너 코코 샤넬의 전성기 이전의 삶과 패션에 대한 열정적인 여성의 이야기.\\n\\n3. \"The September Issue\" (2009): 패션 매거진 Vogue의 2007년 9월호를 준비하는 과정과 편집장 애나 윈투어의 열정과 집착을 담은 다큐멘터리.\\n\\n4. \"Yves Saint Laurent\" (2014): 가장 영향력 있는 디자이너 중 하나인 이브 생 로랑의 성장과 업적']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## with LCEL"
      ],
      "metadata": {
        "id": "Is43BVpWcogd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "왜 LCEL을 사용하면, 아웃풋이 아래쪽으로 떨어지는 예쁜 포멧으로 나오고, 그냥 parser를 부르면 위 처럼 한줄로 가는지 모르겠다.\n",
        "\n",
        "일단, 리스트로는 바뀌지만, 아마도 콤마가 안나오는 것 같다...왜????"
      ],
      "metadata": {
        "id": "ZK4ntinWcrYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# And a query intended to prompt a language model to populate the data structure.\n",
        "prompt_and_model = prompt | compbot\n",
        "output = prompt_and_model.invoke({\"query\": \"패션영화 5개를 추천해줘\"})\n"
      ],
      "metadata": {
        "id": "K6AuXVY8XgQH"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser.invoke(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXVwISLjXgXX",
        "outputId": "5762cf4a-3de4-4d73-86cc-75c96f68ffdc"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. Devil Wears Prada',\n",
              " '2. Crazy Rich Asians',\n",
              " '3. Zoolander',\n",
              " '4. Coco Before Chanel',\n",
              " '5. Sex and the City']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser.parse(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR4MOjErbzBg",
        "outputId": "79a9b756-d1b2-4cbe-d1b4-8f4626d5dce5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1. Devil Wears Prada',\n",
              " '2. Crazy Rich Asians',\n",
              " '3. Zoolander',\n",
              " '4. Coco Before Chanel',\n",
              " '5. Sex and the City']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Todo"
      ],
      "metadata": {
        "id": "CGg0TCX6Fo9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] 다음의 차이점은?  \n",
        "`chat_prompt = chat_prompt_template.format_messages(subject = '군고구마')`  \n",
        "`chat_prompt = chat_prompt_template.format_prompt(subject = '군고구마')`\n",
        "\n",
        "- [ ] 프롬프트 템플릿만으로도 구조화가 되는데, 굳이 스키마를 같이 쓰는 이유는 무엇인가. 정말 모르겠다."
      ],
      "metadata": {
        "id": "1xUIy7s5Fciu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "이걸 LCEL 로 변경하고 싶음...\n",
        "\n",
        "# chain = few_shot_prompt | chatbot()\n",
        "# input = '대학교때는 어땠어?'\n",
        "# # chain.invoke({\"input\": \"대학교때는 어땠어?\"})\n",
        "# chain.invoke(input.to_messages())"
      ],
      "metadata": {
        "id": "W4BoYPchp3-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    FewShotChatMessagePromptTemplate,\n",
        ")\n",
        "examples = [\n",
        "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
        "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
        "]\n",
        "\n",
        "# This is a prompt template used to format each individual example.\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.format())\n",
        "\n",
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
        "        few_shot_prompt,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chatbot.invoke(final_prompt.format(input='7+7'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucvx4qj4LzZp",
        "outputId": "a5f07939-ca77-4d59-ffe9-49431fe57645"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: 2+2\n",
            "AI: 4\n",
            "Human: 2+3\n",
            "AI: 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='AI: Ah, a delightful challenge! The sum of 7 and 7 is 14.')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 final_prompt를 뜯어보면 말이지.. 이런 복잡한 모양이래.\n",
        "```python\n",
        "ChatPromptTemplate(\n",
        "    input_variables=['input'],\n",
        "    messages=[\n",
        "        SystemMessagePromptTemplate(\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=[],\n",
        "                template='사용자의 질문유형에 맞는 대답을 해줘~'\n",
        "            )\n",
        "        ),\n",
        "        FewShotChatMessagePromptTemplate(\n",
        "            examples=[\n",
        "                {'input': '2+2', 'output': '4'},\n",
        "                {'input': '2+3', 'output': '5'},\n",
        "                {'input': '2+4', 'output': '6'},\n",
        "                {'input': '정치인들에 대해서 어떻게 생각해?', 'output': '정치이야기는 싫어'},\n",
        "                {'input': '사내정치에 대해서 어떻게 생각해?', 'output': '정치이야기는 싫어'},\n",
        "                {'input': '종교인들에 대해서 어떻게 생각해?', 'output': '종교이야기는 싫어'},\n",
        "                {'input': '결혼생활에 대해서 어떻게 생각해?', 'output': '결혼은 하면 미친짓, 안하면 바보짓이야'},\n",
        "                {'input': '대학생활에 대해서 어떻게 생각해?', 'output': '대학은 가면 자원낭비 안가면 인생낭비야'},\n",
        "                {'input': '나비에 대한 노래를 불러줘', 'output': '나비야 나비야 이리날아 오너라.'},\n",
        "                {'input': '학교 종에 대한 노래를 불러줘', 'output': '학교종이 떙떙땡 어서 모이자'}\n",
        "            ],\n",
        "            input_variables=['input'],\n",
        "            example_prompt=ChatPromptTemplate(\n",
        "                input_variables=['input', 'output'],\n",
        "                messages=[\n",
        "                    HumanMessagePromptTemplate(\n",
        "                        prompt=PromptTemplate(\n",
        "                            input_variables=['input'],\n",
        "                            template='{input}'\n",
        "                        )\n",
        "                    ),\n",
        "                    AIMessagePromptTemplate(\n",
        "                        prompt=PromptTemplate(\n",
        "                            input_variables=['output'],\n",
        "                            template='{output}'\n",
        "                        )\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        ),\n",
        "        HumanMessagePromptTemplate(\n",
        "            prompt=PromptTemplate(\n",
        "                input_variables=['input'],\n",
        "                template='{input}'\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "AxDL0nUCRKBK"
      }
    }
  ]
}